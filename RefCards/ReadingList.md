# Reading Notes for Data Science

## General Topics


### Visualization

+ K. He & G.Meeden, [Selecting the Number of Bins in a Histogram: A Decision Theoretic Approach](../AppliedDS-UMich/2-InfoVis/p01-HistBins.md)


## Statistics

### Bayesian Approaches

+ D. Spiegelhalter, K. Abrams, J. Myles, [An Overview of the Bayesian Approach](../Notes/p01-Bayesian.md), Chapter 3 in Bayesian Approaches to Clinical Trials and Health-Care Evaluation, 2004



## Artificial Intelligence




## Machine Learning

### General Topics for ML

+ Pedro Domingos, [A Few Useful Things to Know about Machine Learning](../AppliedDS-UMich/3-AML/p0-UsefulThings.md)
+ Ron Kohavi, Randal M. Henne, and Dan Sommerfield, [Practical Guide to Controlled Experiments on the Web: Listen to Your Customers not to the HiPPO](../AppliedDS-UMich/3-AML/p1-ControlledExp.md)
+ S. Kaufman, S. Rosset, & C. Perlich, [Leakage in Data Mining: Formulation, Detection, and Avoidance](../AppliedDS-UMich/3-AML/p3-Leakage.md)
+ Martin Zinkevich, [Rules of Machine Learning: Best Practices for ML Engineering](../AppliedDS-UMich/3-AML/p4-MLRules.md)
+ Maytal Saar-Tsechansky and Foster Provost, [Handling Missing Values when Applying Classification Models](../AppliedDS-UMich/3-AML/p5-Missing.md)
+ [Graphs](../AppliedDS-UMich/5-SocialNet/p2-Graphs.md)


### Machine Learning Models




### Application - Social Networks

+ David Easley and Jon Kleinberg, [Power Laws and Rich-Get-Richer Phenomena](../AppliedDS-UMich/5-SocialNet/p1-PowerLaw.md), Chapter 18 in [Networks, Crowds, and Markets: Reasoning About a Highly Connected World](http://www.cs.cornell.edu/home/kleinber/networks-book/)
+ David Easley and Jon Kleinberg, [The Small-World Phenomenon](../AppliedDS-UMich/5-SocialNet/The Small-World Phenomenon), Chapter 20 in [Networks, Crowds, and Markets: Reasoning About a Highly Connected World](http://www.cs.cornell.edu/home/kleinber/networks-book/)



## Neural Networks

### General Topics for Neural Networks

+ Matthew Stewart, [Introduction to Neural Networks](../ML/MLNN-Hinton/a01-IntroNN.md)
+ Matthew Stewart, [Intermediate Topics in Neural networks](../ML/MLNN-Hinton/a02-IntermediateNN.md)
+ Matthew Stewart, [Neural Network Optimization](../ML/MLNN-Hinton/a03-Optimization.md)
+ Matthew Stewart, [Simple Guide to Hyperparameter Tuning in Neural Networks](../ML/MLNN-Hinton/a04-Hyperparameter.md)
+ Matthew Stewart, [Neural Style Transfer and Visualization of Convolutional Networks](../ML/MLNN-Hinton/a05-VisualCNN.md)
+ Random Nerd, [Delta Learning Rule & Gradient Descent | Neural Networks](../ML/MLNN-Hinton/a06-DeltaRule.md)
+ Drew Rollins, [Delta Function](../ML/MLNN-Hinton/a07-DeltaFunc.md)


### Activation Functions

+ Chris McCormick, [Deep Learning Tutorial - Softmax Regression](../ML/MLNN-Hinton/a08-SoftmaxReg.md)
+ [Softmax Classifier](../ML/MLNN-Hinton/a09-SoftmaxClass.md) in CS231n Convolutional Neural Networks for Visual Recognition, Stanford University



### Convolution Neural Networks

+ Adit Deshpande, [A Beginner's Guide To Understanding Convolutional Neural Networks](../ML/MLNN-Hinton/a10-CNNsGuide.md)



### Deep Learning

+ Adit Deshpande, [The 9 Deep Learning Papers You Need to Know About](../ML/MLNN-Hinton/a11-9Papers.md)





## DataBase for Data Science




## Python Implementation




## Reading List

+ D. Spiegelhalter, K. Abrams, J. Myles, [An Overview of the Bayesian Approach](http://www.medicine.mcgill.ca/epidemiology/hanley/bios602/Bayes/an%20overview%20of%20the%20Bayesian%20approach.pdf), In: [Bayesian Approaches to Clinical Trials and Health-Care Evaluation](http://93.174.95.29/main/791000/1c3cccffb374be94e8940aa087c433c0/%28Statistic%20in%20practice%29%20David%20J.%20Spiegelhalter%2C%20Keith%20R.%20Abrams%2C%20Jonathan%20P.%20Myles%20-%20Bayesian%20Approaches%20to%20Clinical%20Trials%20and%20Health-Care%20Evaluation-Wiley%20%282004%29.pdf), pp.49-120, Wiley, 2004
+ [Bayesian Inference](http://www.stat.cmu.edu/~larry/=sml/Bayes.pdf)
+ S. Ghosh, [Basics of Bayesian Methods](https://www.researchgate.net/profile/Sujit_Ghosh4/publication/45283465_Basics_of_Bayesian_Methods/links/55cce51208ae1141f6b9e8e0/Basics-of-Bayesian-Methods.pdf), in "Methods in molecular biology" (Clifton, N.J.) 620:155-78, 2010
+ [Bayesian Inference](http://www.stat.cmu.edu/~larry/=sml/Bayes.pdf), chapter 12
+ A. Julien-Laferriere, [Hopfield network](http://perso.ens-lyon.fr/eric.thierry/Graphes2010/alice-julien-laferriere.pdf)
+ [Hopfield Model of Neural Network](https://shodhganga.inflibnet.ac.in/bitstream/10603/1760/6/06_chapter%202.pdf), Chapter 2,
+ R. Rojas, [The Hopfield Model](https://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf) in Neural Networks, Springer, 1996
+ J. J. Hopfield, "[Neural networks and physical systems with emergent collective computational abilities](https://www.pnas.org/content/pnas/79/8/2554.full.pdf)", Proceedings of the National Academy of Sciences of the USA, vol. 79 no. 8 pp. 2554–2558, April 1982
+ J. Hopfield, D. Feinstein and R. Palmer, [‘Unlearning’ has a stabilizing effect in collective memories](https://www.researchgate.net/profile/John_Hopfield/publication/16333131_'Unlearning'_has_a_stabilizing_effect_in_collective_memories/links/563fef2f08aec6f17ddb84cc/Unlearning-has-a-stabilizing-effect-in-collective-memories.pdf), Nature 304(5922):158-9 · July 1983
+ G. Hinton and T. Sejnowski, [Optimal perceptual inference](https://papers.cnl.salk.edu/PDFs/Optimal%20Perceptual%20Inference%201983-646.pdf), Proceedings of the IEEE conference on Computer Vision and Pattern Recognition
+ L. Saul, T. Jaakkola, M. Jordan, [Mean field theory for sigmoid belief networks](https://www.jair.org/index.php/jair/article/download/10156/24075), Journal of artificial intelligence research, 1996
+ G. Hinton and T. Sejnowski, [Learning and relearning in Boltzmann machines](https://www.researchgate.net/profile/Terrence_Sejnowski/publication/242509302_Learning_and_relearning_in_Boltzmann_machines/links/54a4b00f0cf256bf8bb327cc/Learning-and-relearning-in-Boltzmann-machines.pdf), In Rumelhart, D. E. and McClelland, J. L., editors, Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations, MIT Press, Cambridge, MA., 1986
+ G. Hinton, R. Salakhutdinov, [A Better Way to Pretrain Deep Boltzmann Machines](http://papers.nips.cc/paper/4610-a-better-way-to-pretrain-deep-boltzmann-machines.pdf), Advances in Neural Information Processing Systems 25 (NIPS 2012)
+ H. Yu, [A gentle tutorial on Restricted Boltzmann Machine and Contrastive Divergence](https://www.researchgate.net/profile/Hongyang_Yu2/publication/315382074_A_gentle_tutorial_on_Restricted_Boltzmann_Machine_and_Contrastive_Divergence/links/58cf1a654585157b6db02f5a/A-gentle-tutorial-on-Restricted-Boltzmann-Machine-and-Contrastive-Divergence.pdf), 2017
+ A. Fischer & C. Igel, [An Introduction to Restricted Boltzmann Machines](https://www.researchgate.net/profile/Asja_Fischer/publication/243463621_An_Introduction_to_Restricted_Boltzmann_Machines/links/0a85e5320cc4851d83000000/An-Introduction-to-Restricted-Boltzmann-Machines.pdf). In Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications: 17th Iberoamerican Congress, CIARP 2012, Buenos Aires, Argentina, September 3-6, 2012. Proceedings (pp.14-36
+ Wythoff, BJ, 1993. [Backpropagation neural networks. A tutorial](https://www.researchgate.net/profile/Samreen_Sid/post/rookie/attachment/59d61d8cc49f478072e97144/AS%3A271736812048384%401441798512764/download/1993+Backpropagation+neural+networks+A+tutorial.pdf), Chemometrics and Intelligent Laboratory Systems, 18: 115-155
+ A. Kurenkov, [A 'Brief' History of Neural Nets and Deep Learning](http://www.andreykurenkov.com/writing/ai/a-brief-history-of-neural-nets-and-deep-learning/), 2015
+ Judea Pearl, [Belief networks revisited](https://ftp.cs.ucla.edu/pub/stat_ser/R175.pdf), Artificial Intelligence, 1993
+ Judea Pearl and Stuart Russell, [Bayesian Networks](https://ftp.cs.ucla.edu/pub/stat_ser/r277.pdf), Technical Report, R-277, 2000
+ Judea Pearl, [A Personal Journey into Bayesian Networks](https://ftp.cs.ucla.edu/pub/stat_ser/r476.pdf), Technical Report, R-476, 2018
+ I. Ben‐Gal, [Bayesian Networks](https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470061572.eqr089), Encyclopedia of Statistics in Quality and Reliability 2008
+ M. Wellman and M. Henrion, [Explaining 'explaining away'](https://pdfs.semanticscholar.org/bffd/c2699cba4893bd6a6befdc8f46f6f23f33d1.pdf?_ga=2.60626154.639362258.1581809305-1938421553.1581809305), IEEE Transactions on Pattern Analysis and Machine Intelligence, 15(3):287-292, April 1993
+ G. Hinton, P. Dayan, B. Frey, and R. Neal, [The wake-sleep algorithm for unsupervised neural networks](https://www.cs.toronto.edu/~hinton/csc2535/readings/ws.pdf), Science, Vol. 268, Issue 5214, pp. 1158-1161, 1995
+ A. Ng and M. Jordan, [On discriminative vs. generative classifiers: a comparison of logistic regression and naive bayes](http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf), Adv. Neural Inf. Proc. Syst. 14, 841 (2002)
+ C. Bishop and J. Lasserre, [Generative or Discriminative? Getting the Best of Both Worlds](https://www.researchgate.net/profile/David_Heckerman/publication/228993892_Generative_or_Discriminative_Getting_the_Best_of_Both_Worlds/links/5547741b0cf2e2031b36b897/Generative-or-Discriminative-Getting-the-Best-of-Both-Worlds.pdf), BAYESIAN STATISTICS 8, pp. 3–24, 2007
+ R. Tibshirani, [Modeling Basics: Assessment, Selection, and Complexity](https://www.stat.cmu.edu/~ryantibs/statml/review/modelbasics.pdf), Statistical Machine Learning, Spring 2015



