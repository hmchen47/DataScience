# Programming Assignment: Regularized Linear Regression and Bias/Variance

### 1 Regularized Linear Regression

+ implement regularized linear regression to predict the amount of water flowing out of a dam using the change of water level in a reservoir

+ Observe diagnostics of debugging learning algorithms and examine the effects of bias v.v. variance


### 1.1 Visualizing the dataset

+ visualizing the dataset containing historical records on the change in the water level, $x$, and the amount of water flowing out of the dam, $y$

+ Three parties of dataset
    + a training set to learn: `X`, `y`
    + a cross validation set for determining the regularization parameter: `Xval`, `yval`
    + a test set for evaluating performance, "unseen" examples dueing training: `Xtest`, `ytest`

+ `ex5.m` plots the training data

+ implement linear regression and use to fit a straight line to the data and plot learning curve

+ implement polynomial regression to find a better fit to the data


### 1.2 Regularized linear regression cost function

+ Cost function of regularized linear regression

    $$J(\theta) = \dfrac{1}{2m} \left( \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 \right) + \dfrac{\lambda}{2m} \left( \sum_{j=1}^n \theta_j^2 \right)$$

    + $\lambda\;$: regularization parameter to control the degree of regularization [prevent from overfitting]
    + put a penalty on the overall cost $J$
    + $\theta\uparrow \implies J \uparrow$

+ Complete code in `linearRegCostFunction.m`
    + write a function to calculate the regularized linear regressioncost function
    + try vectorized than looped
    + `ex5.m` runs the cost function using theta initialized at `[1; 1]`


### 1.3 Regularized linear regression gradient

+ The partial derivatives of regularized linear regression's cost for $\theta_j$

    $$\dfrac{\partial J(\theta)}{\partial \theta_0}  = \begin{cases} \dfrac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} & \text{for } j = 0 \\\\ \dfrac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} + \dfrac{\lambda}{m} \theta_j & \text{for } j \geq 1 \end{cases}$$

+ Add code in `linearRegCost.m` to calculate the the gradient, `grad`

+ `ex.m` run the gradient code with theta initialized at `[1; 1]` and expect gradient of `[-15.30; 598.250]`


### 1.4 Fitting linear regression



### 2 Bias-variance



### 2.1 Learning curves



### 3 Polynomial regression



### 3.1 Learning Polynomial Regression



### 3.2 Adjusting the regularization parameter (Optional)



### 3.3 Selecting $\lambda$ using a cross validation set



### 3.4 Computing test set error (Optional)



### 3.5 Plotting learning curves with randomly selected (Optional)



### Programming Ex.5

Proposed erratum: the Optional exercise (Section 3.5) instructs you to select i examples from the cross-validation set. Shouldn't you always validate on the full cross-validation set as in section 2.1?

Other miscellany:

shouldn't it be "vs." instead of "v.s."?
p. 3 "overal"
p. 6 "wil"
p. 7 "For use polynomial regression [sic]"
p. 7 "zero-eth" - shouldn't this be "zero-th"?
p. 9 "where the low training error is low [sic]"

#### Debugging Tip

The submit script, for all the programming assignments, does not report the line number and location of the error when it crashes. The follow method can be used to make it do so which makes debugging easier.

Open ex5/lib/submitWithConfiguration.m and replace line:

```matlab
 fprintf('!! Please try again later.\n');
```

(around 28) with:

```matlab
fprintf('Error from file:%s\nFunction:%s\nOn line:%d\n', e.stack(1,1).file,e.stack(1,1).name, e.stack(1,1).line );
```

That top line says '!! Please try again later' on crash, instead of that, the bottom line will give the location and line number of the error. This change can be applied to all the programming assignments.


### Ex5 Tutorials

#### [ex5 tutorial linearRegCostFunction](https://www.coursera.org/learn/machine-learning/discussions/all/threads/UAv1DB62EeWd3iIAC7VAtA)

Here is a brief tutorial for the `linearRegCostFunction()`.

We last did a linear regression exercise back in ex1, so start with these two tutorials for computeCost() and gradientDescent(). Since they're vectorized, they work equally well for any multiple-variable linear regression.

[computeCost tutorial](https://www.coursera.org/learn/machine-learning/discussions/t35D1xn3EeWA7CIAC5WDNQ)

[gradientDescent tutorial](https://www.coursera.org/learn/machine-learning/discussions/-m2ng_KQEeSUBCIAC9QURQ)

You only need the first three steps of the gradientDescent() tutorial, plus scaling by 1/m (ignore the 'alpha' variable, it is not used in this exercise). That's gives us the gradient. Since we let fmincg() perform gradient descent for us, we just have to compute the cost and gradient. We don't use a for-loop over the number of iterations, or use any learning rate. The fmincg() function does that for us.

So now you've got unregularized cost J, and unregularized gradient 'grad'.

For the cost regularization:

+ Set theta(1) to 0.
+ Compute the sum of all of the theta values squared. One handy way to do this is sum(theta.^2). Since theta(1) has been forced to zero, it doesn't add to the regularization term.
+ Now scale this value by lambda / (2*m), and add it to the unregularized cost.


For the gradient regularization:

+ The regularized gradient term is theta scaled by (lambda / m). Again, since theta(1) has been set to zero, it does not contribute to the regularization term.
+ Add this vector to the unregularized portion.


That's it. Here is a [test case](https://www.coursera.org/learn/machine-learning/discussions/O25D0QykEeWZSyIAC5bWOg) for this function


Other posts:

+ The unregularized part of cost is 1.3533.
+ The regularized part of the cost is 0.33833.
+ Use `sum()` when you use element-wise multiplication. <br/>
    When you use a vector multiplication, the sum is included automatically.
+ Perhaps compare your code with what is in [the tutorial](https://www.coursera.org/learn/machine-learning/discussions/m0ZdvjSrEeWddiIAC9pDDA) for this exercise
+ That use of "costFunction" is done using the "anonymous function" method. It is really more of a function pointer than a real function. <br/> In ex5, the function "trainLinearReg()" handles this for you. <br/> Open up trainLinearReg.m in a text editor, and look at lines 13 through 19. You don't have to change anything here. trainLinearReg() calls `fmincg()` using your cost function. <br/>Your learningCurve() and validationCurve() functions just call trainLinearReg() to get the job done.


#### [Tutorial for polyFeatures()](https://www.coursera.org/learn/machine-learning/discussions/weeks/6/threads/YbO2RaVGEeaCbg44JUM1Vg)

There are a couple of different methods that work for the `polyFeatures()` function.

One is to use the `bsxfun()` function, with the @power operator, like this:

```matlab
X_poly = bsxfun(@power, vector1, vector2)
```

... where vector1 is a column vector of the feature values 'X', and vector2 is a row vector of exponents from 1 to 'p'.

Other options involve using the element-wise exponent operator '.^', and converting both X and the vector of exponent values into equal-sized matrices by multiplying each by a vectors of all-ones.


#### [ex5: tips for learningCurve()](https://www.coursera.org/learn/machine-learning/discussions/weeks/6/threads/Y_DZmpkgEeWNbBIwwhtGwQ)

This thread is the tutorial for the `learningCurve()` function.

The thread is closed to comments (to prevent issues with the Forum software over time). If you have questions, please post them in a new thread.

------------------------

Note: Almost all of the code you need for this function is provided in the code examples and hints in the `learningCurve.m` script.

Step 1) Use a for-loop to iterate over the length of the training set. The "Hint" in `learningCurve.m` gives you the code to use.

Step 2) Create a subset of the "X" matrix and the 'y' vector, using the elements 1 through 'i'. The first "Note" in `learningCurve.m` gives you the code to use. This causes the training set size to increase by one for each iteration through the training set. You will use this subset for training (Step 3) and measuring the training set error (Step 4).

Step 3) Use the trainLinearReg() function to learn the theta vector for the current size of training set (see page 6 of ex5.pdf).

Step 4) Then use your cost function to compute the training set error. Do not include regularization. Store the training set cost in error_train(i).

Step 5) Then use your cost function to compute the validation set error, using Xval and yval. Do not include regularization. Do not create any subsets of the validation set. Store the validation set error in error_val(i).

Tips:

+ Use the lambda parameter - from the `learningCurve()` parameter list - every time you call trainLinearReg().
+ __do not__ set lambda = 0 inside the `learningCurve()` function. You are going to experiment with different lambda values in `ex5.m`, and the submit grader doesn't use lambda = 0. So do not hard-code lambda = 0 inside the `learningCurve()` function.
+ When you compute the training set error and the validation set error, use your cost function with a zero for the lambda parameter. We want to measure the error in the hypothesis, without including any additional penalties for the theta values.
+ When you run the `ex5` script, you may get some "divide by zero" warnings. These are expected and normal. `fmincg()` generates "divide by zero" warnings whenever the training set has only one or two examples. Do not worry about it.


#### [Validation curve question](https://www.coursera.org/learn/machine-learning/discussions/all/threads/AdGhzAX1EeWyEyIAC7PmUA/replies/7XjBAQ-MEeWUtiIAC9TNkg?page=2)

For `validationCurve()`, you always use the entire training set, and the entire validation set. The only item you are varying is the value of lambda when you compute theta on the training set.

Also, do not use regularization when measuring the training error and the validation error.












