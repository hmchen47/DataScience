# Programming Assignment: Neural Network Learning

### 1. Neural Network

+ Implement the backpropagation algorithm to learn the parameters for the neural network

### 1.1 Visualizing the data

+ `ex4.m`
  + load the data
  + display on a 2-dim plot with `displayData` function

+ `ex3ata1.mat`
  + 5000 training examples
  + sample: 20 pixel by 20 pixel grayscale images of the digit
  + pixel: a floating point number indicating the grayscale intensity at that location
  + The 20 by 20 grid of pixels _unrolled_ into a 400-dimensional vector

+ Matrix `X`
  + A 5000 by 400 matrix
  + each row = a training example of a handwritten digit  image

  $$X = \begin{bmatrix} - & (x^{(1)})^T & - \\ - & (x^{(2)})^T & - \\ & \vdots & \\ - & (x^{(m)})^T & - \end{bmatrix}$$

+ Vector `y`
  + 5000-dim vector
  + containing labels for the training set
  + mapping the digit zero to the value 10
  + "0" digit labeled as "10" while the digits "1" to "9" labeled as "1" to "9" in the natural order


### 1.2 Model representation

+ 3-layer Neural Network
  + an input layer, a hidden layer, and an output layer
  + input layer: 400 units (image size: $20 \times 20$)
  + not counting the extra bias unit which always outputs +1)
  + hidden layer: 25 units
  + output layer: 10 units (10 digit classes)

  <div style="display:flex;justify-content:center;align-items:center;flex-flow:row wrap;">
    <div><a href="https://s3.amazonaws.com/spark-public/ml/exercises/on-demand/machine-learning-ex4.zip">
      <img src="images/e04-01.png" style="margin: 0.1em;" alt="It has 3 layers { an input layer, a hidden layer and an output layer. Recall that our inputs are pixel values of digit images. Since the images are of size 20  20, this gives us 400 input layer units (not counting the extra bias unit which always outputs +1)." title="Neural Network Model" width="250">
    </a></div>
  </div>

+ `extweights.mat`
  + a set of network parameters: $\Theta^{(1)}, \Theta^{(2)}$
  + variables: Theta1, Theta2

+ Loading dataset

  ```matlab
  % Load saved matrices from file
  load('ex4weights.mat');

  % The matrices Theta1 and Theta2 will now be in your workspace
  % Theta1 has size 25 x 401
  % Theta2 has size 10 x 26
  ```


### 1.3 Feedbackforward and cost function

+ Implement the cost function and gradient for the neural network

+ complete thr code in `nnCostFunction.m` to return the cost

+ Cost function for the neural network (w/o regularization)

  $$J(\Theta) = \dfrac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \left[ -y^{(i)} \log((h_\theta(x^{(i)}))_k) - (1 - y^{(i)}_k) \log(1 - (h_\theta(x^{(i)}))_k) \right]$$

+ Formula for the 3-layer neural network
  + $K = 10\;$: the total number of possible labels
  + $h_\theta(x^{(i)})_k = a^{(3)}_k$: the activation (output value) of the $k$-th output unit
  + the original labels: $1, 2, \ldots, 10$

    $$y = \underbrace{\begin{bmatrix} 1 \\ 0 \\ 0 \\ \vdots \\ 0 \end{bmatrix}, \quad \begin{bmatrix} 0 \\ 1 \\ 0 \\ \vdots \\ 0 \end{bmatrix}, \quad \cdots \quad,  \begin{bmatrix} 0 \\ 0 \\ 0 \\ \vdots \\ 1 \end{bmatrix}}_{\text{10 items}}$$
  + E.g. $x^{(i)}$ as an image of the digit 5 $\implies$ the corresponding $y^{(i)}$ should be a 10-dim vector with $y_5 =`$ and the other elements equal to 0.

+ Implement the feedforward computation that computes $h_\theta(x^{(i)})$ for every sample $i$ and sum the cost over all examples

+ Code should also work for a dataset of any size, with any number of labels

+ Implementation Note:
  + add the column 1's to the `X` matrix
  + the parameters for each units in the neural network: Theta1 and Theta2 as one row
  + the first row of Theta1 corresponds to tthe first hidden unit in the second layer
  + able to use a for-loop over the examples to compute the cost

+ `ex4,m` calls `nnCostFunction` using the loaded set of parameters for Theta1 and Theta2.  The cost is about 0.287629.


### 1.4 Regularized cost function

+ The cost function for neural network with regularization

  $$J(\Theta) = \dfrac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \left[ -y^{(i)} \log((h_\theta(x^{(i)}))_k) - (1 - y^{(i)}_k) \log(1 - (h_\theta(x^{(i)}))_k) \right] + \dfrac{\lambda}{2m} \left[ \sum_{j=1}^{25}\sum_{k=1}^{400} (\Theta^{(1)}_{j,k})^2 + \sum_{j=1}^{10}\sum_{k=1}^{25} (\Theta^{(2)}_{j,k})^2 \right]$$

  + assume that the cost function for 3-layer
  + The code can be generalized to any number of input units, hidden units, and output units
  + explicitly listed the indices for $\Theta^{(1)}$ and $\Theta^{(2)}$ for clarity

+ Generalized cost function with regularization

  $$J(\Theta) = −\dfrac{1}{m} \sum_{t=1}^m \sum_{k=1}^K \left[ y^{(t)}_k \log (h_\Theta(x^{(t)}))_k + (1−y^{(t)}_k) \log (1 − h_\Theta(x^{(t)})_k) \right] + \dfrac{\lambda}{2m} \sum_{l=1}^{L−1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l + 1}} (\Theta^{(l)}_{j,i})^2$$

+ for the matrices Theta1 and Theta2, the corresponds to the first column of each matrix.

+ compute the unregularized cost function $J$ using existing `nnCostFunction.m` and then add the cost for the regularization terms.

+ `nnCostFunction` using the loaded set of parameters for Theta1 and Theta2, and $\lambda = 1$.  The cost is about 0.383770.



### 2. Backpropagation

+ implement the backpropogation algorithm to compute the gradient for the neural network cost function

+ complete the  `nnCostFunction.m` to return the appropriate value for `grad`

+ Able to train the neural network by $\min_\Theta J(\Theta)$ with `fminunc`


### 2.1 Sigmoid gradient




### 2.2 Random initialization



### 2.3 Backpropagation



### 2.4 Gradient checking



### 2.5 Regularized Neural Networks



### 2.6 Learning parameters using `fmincg`



### 3. Visualizing the hidden layer

### 3.1 Optional exercise



### Programming Ex.4

This is the toughest exercise so far, mainly because you have to implement a series of steps, each subject to error, before you get any feedback. These techniques may help:

See the tutorial below (developed for the Spring 2014 session).

__Use the command line__. The command line is your friend. Run enough of `ex4.m` to initialize `X`, `y`, `Theta1`, and `Theta2`, then work one statement or operation at a time to get the results you want. When you get a statement working, transfer it to nnCostFunction--and save the file.

__Use dimensions__. Use `size()` to check the dimensions of vectors and matrices to determine order of multiplication and whether a transpose is needed. This is especially valuable for the gradients. Keep in mind that the gradient matrices are the same size as Theta1 and Theta2. Also note that you will need to do some things that may seem counter-intuitive, like multiplying a $m \times 1$ vector by a $1 \times n$ vector to get an $m \times n$ matrix.

You may find it helpful to note the dimensions of each matrix in a comment on the line of code, as you define it and use it, e.g.:

```matlab
Theta1 = reshape(.....)   % (nhn x (n+1))  
a = b * c  % dimcheck: (nhn x (n+1))  = (nhn x m) * (m x (n+1))  
```

+ Do not hard-code. Specifically, do not hard-code the size of the 'binarized' y vector to 10. It will work fine for the initial tests, but will blow up with cryptic error messages later on.
+ If you get stuck on gradients, try working on a smaller, easier to grasp problem. You can steal code from checkNNGradients and paste it into the command line to get a 3-5-3 network that's a bit more manageable.
+ Full vectorization of backprop

If you want to get rid of the loop over the training samples in back propagation algorithm, you are facing the problem to create a logical vector for y for all training examples. Some smart guy from the spring 2013 instance of this course came up with the following elegant solution for this task

```matlab
yv=[1:num_labels] == y
```

(This does not seem to work in Octave 3.2.4, I use 3.6.4 Doesn't work on 3.4 either.)

After getting this, it was pretty straightforward to vectorize the loop. I could transform each line from my for-loop 1:1 to the vectorized code.

Note, the above expression relies on the [broadcasting feature of Octave](http://www.gnu.org/software/octave/doc/interpreter/Broadcasting.html).

A call to `bsxfun` is an equivalent solution that explicitly apply a broadcast:

```matlab
yv = bsxfun(@eq, y, 1:num_labels);
```

A different solution - kind of slow (this loop alone took about half the time of my vectorized solution on a mac laptop):

```matlab
yv = zeros(m, num_labels);
for i = 1:m
  yv(i, y(i)) = 1;
end
```

Using vectorization speeds up the code considerably.

Another method for generating the y matrix, this time looping over the labels:

```matlab
y_matrix = [];   % create a null matrix
for i = 1:num_labels
    y_matrix = [y_mat y == i];
end
```

Another vectorized one-line method (using vectorized indexing of an eye matrix)- Spring 2014 session:
```matlab
y_matrix = eye(num_labels)(y,:);  % works for Octave
...or
all_combos = eye(num_labels);
y_matrix = all_combos(y,:)        % works for Matlab
```

This method uses an indexing trick to vectorize the creation of 'y_matrix', where each element of 'y' is mapped to a single-value row vector copied from an eye matrix.

__FYI: Misleading Formula in Ex4 pdf for regularization term of cost__

The summation indexes for Theta 1 and 2 should be from 2 to 26 and 2 to 401 respectively.

Tutorial for Ex.4 Forward and Back-propagation (Spring 2014 session)

This tutorial outlines the process of accomplishing the goals for Programming Exercise 4. The purpose is to create a collection of all the useful yet scattered and obscure knowledge that otherwise would require hours of frustrating searches.This tutorial is targeted solely at vectorized implementations. If you're a looper, you're doing it the hard way, and you're on your own.I'll use the less-than-helpful greek letters and math notation from the video lectures in this tutorial, though I'll start off with a glossary so we can agree on what they are. I will also suggest some common variable names, so students can more easily get help on the Forum. It is left to the reader to convert these lines into program statements. You will need to determine the correct order and transpositions for each matrix multiplication. Most of this material appears in either the video lectures, slides, course wiki, or the ex4.pdf file, though nowhere else does it all appear in one place. __Glossary__:Each of these variables will have a subscript, noting which NN layer it is associated with.Θ: A matrix of weights to compute the inner values of the neural network. When we used single-vector theta values, it was noted with the lower-case character θ.z : is the result of multiplying a data vector with a Θ matrix. A typical variable name would be "z2".a : The "activation" output from a neural layer. This is always generated using a sigmoid function g() on a z value. A typical variable name would be "a2".δ : lower-case delta is used for the "error" term in each layer. A typical variable name would be "d2".Δ : upper-case delta is used to hold the sum of the product of a δ value with the previous layer's a value. In the vectorized solution, these sums are calculated automatically though the magic of matrix algebra. A typical variable name would be "Delta2".Θ gradient : This is the thing we're looking for, the partial derivative of theta. There is one of these variables associated with each Δ. These values are returned by nnCostFunction(), so the variable names must be "Theta1_grad" and "Theta2_grad".g() is the sigmoid function.g′() is the sigmoid gradient function.Tip: One handy method for ignoring a column of bias units is to use the notation `SomeMatrix(:,2:end)`. This selects all of the rows of a matrix, and omits the entire first column.Here we goNearly all of the editing in this exercise happens in `nnCostFunction.m`. Let's get started.

__A note regarding the sizes of these data objects__:See the Appendix at the bottom of the tutorial for information on the sizes of the data objects. __A note regarding bias units, regularization, and back-propagation__:There are two methods for handing the bias units in the back-propagation and gradient calculations. I've described only one of them here, it's the one that I understood the best. Both methods work, choose the one that makes sense to you and avoids dimension errors. It matters not a whit whether the bias unit is dropped before or after it is calculated - both methods give the same results, though the order of operations and transpositions required may be different. Those with contrary opinions are welcome to write their own tutorial. __Forward Propagation__:We'll start by outlining the forward propagation process. Though this was already accomplished once during Exercise 3, you'll need to duplicate some of that work because computing the gradients requires some of the intermediate results from forward propagation.

Step 1 - Expand the 'y' output values into a matrix of single values (see ex4.pdf Page 5). This is most easily done using an eye() matrix of size num_labels, with vectorized indexing by 'y', as in "eye(num_labels)(y,:)". Discussions of this and other methods are available in the Course Wiki - Programming Exercises section. A typical variable name would be "y_matrix".

Step 2 - perform the forward propagation:a1 equals the X input matrix with a column of 1's added (bias units)z2 equals the product of a1 and Θ1a2 is the result of passing z2 through g()a2 then has a column of 1st added (bias units)z3 equals the product of a2 and Θ2a3 is the result of passing z3 through g()__Cost Function, non-regularized__

Step 3 - Compute the unregularized cost according to ex4.pdf (top of Page 5), (I had a hard time understanding this equation mainly that I had a misconception that y(i)k is a vector, instead it is just simply one number) using a3, your ymatrix, and m (the number of training examples). Cost should be a scalar value. If you get a vector of cost values, you can sum that vector to get the cost.Remember to use element-wise multiplication with the log() function.Now you can run `ex4.m` to check the unregularized cost is correct, then you can submit Part 1 to the grader.

__Cost Regularization__

Step 4 - Compute the regularized component of the cost according to ex4.pdf Page 6, using Θ1 and Θ2 (ignoring the columns of bias units), along with λ, and m. The easiest method to do this is to compute the regularization terms separately, then add them to the unregularized cost from Step 3.You can run `ex4.m` to check the regularized cost, then you can submit Part 2 to the grader. __Sigmoid Gradient and Random Initialization__

Step 5 - You'll need to prepare the sigmoid gradient function g′(), as shown in ex4.pdf Page 7You can submit Part 3 to the grader.

Step 6 - Implement the random initialization function as instructed on ex4.pdf, top of Page 8. You do not submit this function to the grader. __Backpropagation__

Step 7 - Now we work from the output layer back to the hidden layer, calculating how bad the errors are. See ex4.pdf Page 9 for reference.δ3 equals the difference between a3 and the y_matrix.δ2 equals the product of δ3 and Θ2 (ignoring the Θ2 bias units), then multiplied element-wise by the g′() of z2 (computed back in Step 2).Note that at this point, the instructions in ex4.pdf are specific to looping implementations, so the notation there is different.Δ2 equals the product of δ3 and a2. This step calculates the product and sum of the errors.Δ1 equals the product of δ2 and a1. This step calculates the product and sum of the errors.

__Gradient, non-regularized__

Step 8 - Now we calculate the non-regularized theta gradients, using the sums of the errors we just computed. (see ex4.pdf bottom of Page 11)Θ1 gradient equals Δ1 scaled by 1/mΘ2 gradient equals Δ2 scaled by 1/mThe `ex4.m` script will also perform gradient checking for you, using a smaller test case than the full character classification example. So if you're debugging your nnCostFunction() using the "keyboard" command during this, you'll suddenly be seeing some much smaller sizes of X and the Θvalues. Do not be alarmed.If the feedback provided to you by `ex4.m` for gradient checking seems OK, you can now submit Part 4 to the grader. __Gradient Regularization__

Step 9 - For reference see ex4.pdf, top of Page 12, for the right-most terms of the equation for j>=1.Now we calculate the regularization terms for the theta gradients. The goal is that regularization of the gradient should not change the theta gradient(:,1) values (for the bias units) calculated in Step 8. There are several ways to implement this (in Steps 9a and 9b). Method 1: 9a) Calculate the regularization for indexes (:,2:end), and 9b) add them to theta gradients (:,2:end).Method 2: 9a) Calculate the regularization for the entire theta gradient, then overwrite the (:,1) value with 0 before 9b) adding to the entire matrix.Details for Steps 9a and 9b9a) Pick a method, and calculate the regularization terms as follows:(λ/m)∗Θ1 (using either Method 1 or Method 2)...and(λ/m)∗Θ2 (using either Method 1 or Method 2)9b) Add these regularization terms to the appropriate Θ1 gradient and Θ2 gradient terms from Step 8 (using either Method 1 or Method 2). Avoid modifying the bias unit of the theta gradients. Note: there is an errata in the lecture video and slides regarding some missing parenthesis for this calculation. The ex4.pdf file is correct. The `ex4.m` script will provide you feedback regarding the acceptable relative difference. If all seems well, you can submit Part 5 to the grader.Now pat yourself on the back.

__Appendix__:

Here are the sizes for the character recognition example, using the method described in this tutorial. a1: 5000x401z2: 5000x25a2: 5000x26a3: 5000x10d3: 5000x10d2: 5000x25Theta1, Delta1 and Theta1grad: 25x401Theta2, Delta2 and Theta2grad: 10x26Note that the `ex4.m` script uses a several test cases of different sizes, and the submit grader uses yet another different test case.

### Debugging Tip

The submit script, for all the programming assignments, does not report the line number and location of the error when it crashes. The follow method can be used to make it do so which makes debugging easier.

Open `ex4/lib/submitWithConfiguration.m` and replace line:

```matlab
 fprintf('!! Please try again later.\n');
```

(around 28) with:

```matlab
fprintf('Error from file:%s\nFunction:%s\nOn line:%d\n', e.stack(1,1).file,e.stack(1,1).name, e.stack(1,1).line );
```

That top line says '!! Please try again later' on crash, instead of that, the bottom line will give the location and line number of the error. This change can be applied to all the programming assignments.

#### Tips for classifying your own images:

There's no documentation on how the images were prepared for this course. These tips may be helpful.

+ The images must be gray-scale with 20x20 pixels.
+ The image pixels are scaled (or normalized) so that -1.0 is black, 0.0 is grey, and +1.0 is white. However, nearly all of the pixels are in the 0.0 to +1.0 range. The backgrounds are grey, and the image "pen strokes" are white.
+ Your images must use the same value range as the training data, otherwise the NN will not be able to classify them.
+ Center the digit image so it does not use the two pixels around the borders.


### Bonus: Neural Network does not need order in pixels of an image as humans do

The pixels order (as a human sees them) is not necessary (or relevant) for a Neural Network.

You can test it with a modified `ex3.m` program below (you can call it `ex3_rand.m`)

The program has a randomize pixel position step "scrambling" the 400 vector positions BEFORE the training. As long as you keep the same pixel position when predicting, the results are the same.

It is interesting to "see" how prediction perfectly works with a scrambled picture!

You can test it once you have submitted OK the `ex3.m` program (meaning that you have the oneVsAll function working OK first).

#### `ex3_rand.m` is a modified version of `ex3.m`

```matlab
ex3_rand.m (is a modified version of ex3.m to scramble pixels/features)
%
%% Machine Learning Online Class - Exercise 3 | Randomize Features

%% Initialization
clear; close all; clc

%% Setup the parameters you will use for this part of the exercise
input_layer_size  = 400; % 20x20 Input Images of Digits
num_labels = 10;         % 10 labels, from 1 to 10   
                         % (note that we have mapped "0" to label 10)

%% =========== Part 1: Loading and Visualizing Data =============
%  We start the exercise by first loading and visualizing the dataset. 
%  You will be working with a dataset that contains handwritten digits.
%

% Load Training Data
fprintf('Loading and Visualizing Data ...\n')

load('ex3data1.mat'); % training data stored in arrays X, y
m = size(X, 1);

% Randomly select 100 data points to display
rand_indices = randperm(m, 100);
sel = X(rand_indices,:);

displayData(sel);

fprintf('Program paused. Press enter to continue.\n');
pause;

%% ============ Part 2: Vectorize Logistic Regression ============
%  In this part of the exercise, you will reuse your logistic regression
%  code from the last exercise. You task here is to make sure that your
%  regularized logistic regression implementation is vectorized. After
%  that, you will implement one-vs-all classification for the handwritten
%  digit dataset.
%

% Added to randomize features (to probe that is irrelevant)
fprintf('\nRandomizing columns...\n');
X_rand = X(:, randperm(size(X,2)));

fprintf('\nTraining One-vs-All Logistic Regression...\n')

lambda = 0.1;
[all_theta] = oneVsAll(X_rand, y, num_labels, lambda);

fprintf('Program paused. Press enter to continue.\n');
pause;


%% ================ Part 3: Predict for One-Vs-All ================
%  After ...
pred = predictOneVsAll(all_theta, X_rand);

fprintf('\nTraining Set Accuracy:%f\n', mean(double(pred == y)) * 100);

%% ============ Part 4: Predict Random Samples ============
%  To give you an idea of the network's output, you can also run
%  through the examples one at the a time to see what it is predicting.

%  Randomly permute examples
rp = randperm(m);

for i = 1:m
   % Display 
    fprintf('\nDisplaying Example Randomized Image\n');
    displayData(X_rand(rp(i),:));

    pred = predictOneVsAll(all_theta, X_rand(rp(i),:));
    fprintf('\nNeural Network Prediction:%d (label%d)\n', pred, y(rp(i)));

   % Pause
    fprintf('Program paused. Press enter to continue.\n');
    pause;
end
```

#### Why the order is Irrelevant for the Neural-Network

You can see that the order of the pixels is irrelevant as long as you are consistent in two ways:

1. Between samples. Each feature should mean the same pixel. You can not change the pixel location for one sample and not for the others. You can scramble them but you have to keep the "scrambling" fixed for the entire samples.
2. Between labels. Each label should represent the same digit for its group of samples. Meaning a digit four is a four for all of the samples you labeled as four and can not change it.It does not matter if the pixels are 'scrambled", it is a four.


#### Equivalent example of order irrelevancy

An equivalent example is the order of variable names when solving a system of equations. It does not matter how you call a variable or the order as long as you are consistent through out the solution.

For example, this:

$\begin{array}{rcl} 3x_1 + 4x_2 &=& 26 \\ 2x_1 -3x_2 &=& -11 \end{array}$

Solution: $x_1=2; x_2=5$

...is equivalent to:

$\begin{array}{rcl} 3x_2 + 4x_1 &=& 26 \\ 2x_2 - 3x_1 &=& -11 \end{array}$

Solution: $x_2 = 2; x_1 = 5$

...also you can "scramble" the terms and "labels"

$\begin{array}{rcl} -3x_1 + 2x_2 &=& -11 \\ 4x_1 + 3x_2 &=& 26 \end{array}$

Solution: $x_1 = 5; x_2 = 2$

It has to do with convention. Any convention as long as it is the same all the way through.


## [ex4 Tutorial for forward propagation and cost](https://www.coursera.org/learn/machine-learning/programming/AiHgN/neural-network-learning/discussions/threads/QFnrpQckEeWv5yIAC00Eog)

Note: this thread is closed to comments. If you have a question, please post it in the Week 5 Discussion Forum area.

This tutorial uses the vectorized method. If you're using a for-loop over the training examples, you're doing it the hard way, and you're on your own.

A note on Errata: The cost and gradient equations in the ex4.pdf file are correct. There may be some errata in the video lectures. Check the Course Wiki to be sure.

I'll use the less-than-helpful greek letters and math notation from the video lectures in this tutorial, though I'll start off with a glossary so we can agree on what they are. I will also suggest some common variable names, so students can more easily get help on the Forum.

It is left to the reader to convert these descriptions into program statements. You will need to determine the correct order and transpositions for each matrix multiplication, so that the result has the correct size.

__Glossary:__

Each of these variables will have a subscript, noting which NN layer it is associated with.

+ $\Theta\;$: A Theta matrix of weights to compute the inner values of the neural network. When we used a vector theta, it was noted with the lower-case theta character $\theta$.
+ $z\;$ is the result of multiplying a data vector with a Θ matrix. A typical variable name would be "z2".
+ $a\;$: The "activation" output from a neural layer. This is always generated using a sigmoid function `g()` on a z value. A typical variable name would be "a2".
+ $\delta\;$: lower-case delta is used for the "error" term in each layer. A typical variable name would be "d2".
+ $\Delta\;$: upper-case delta is used to hold the sum of the product of a $\delta$ value with the previous layer's $a$ value. In the vectorized solution, these sums are calculated automatically though the magic of matrix algebra. A typical variable name would be "Delta2".
+ $\Theta$`_`gradient: This is the thing we're solving for, the partial derivative of theta. There is one of these variables associated with each $\Delta$. These values are returned by `nnCostFunction()`, so the variable names must be "Theta1_grad" and "Theta2_grad".
+ $g()\;$: the sigmoid function.
+ $g^\prime()\;$: the sigmoid gradient function.

Tip: One handy method for excluding a column of bias units is to use the notation SomeMatrix(:,2:end). This selects all of the rows of a matrix, and omits the entire first column.

See the Appendix at the bottom of the tutorial for information on the sizes of the data objects.

A note regarding bias units, regularization, and back-propagation:

There are two methods for handing exclusion of the bias units in the Theta matrices in the back-propagation and gradient calculations. I've described only one of them here, it's the one that I understood the best. Both methods work, choose the one that makes sense to you and avoids dimension errors. It matters not a whit whether the bias unit is excluded before or after it is calculated - both methods give the same results, though the order of operations and transpositions required may be different. Those with contrary opinions are welcome to write their own tutorial.

__Forward Propagation__:

We'll start by outlining the forward propagation process. Though this was already accomplished once during Exercise 3, you'll need to duplicate some of that work because computing the gradients requires some of the intermediate results from forward propagation. Also, the y values in ex4 are a matrix, instead of a vector. This changes the method for computing the cost $J$.

1. Expand the `y` output values into a matrix of single values (see ex4.pdf Page 5). This is most easily done using an `eye()` matrix of size num_labels, with vectorized indexing by `y`. A useful variable name would be `y_matrix`, as this...

    ```matlab
    y_matrix = eye(num_labels)(y,:)
    ```

    Note: For MATLAB users, this expression must be split into two lines, such as...

    ```matlab
    eye_matrix = eye(num_labels);
    y_matrix = eye_matrix(y,:);
    ```

2. Perform the forward propagation:
    + $a_1\;$: equals the X input matrix with a column of 1's added (bias units) as the first column.
    + $z_2\;$ equals the product of $a_1$ and $\Theta_1$
    + $a_2$ is the result of passing $z_2$ through $g()$
    + Then add a column of bias units to $a_2$ (as the first column). <br/>
      NOTE: Be sure you DON'T add the bias units as a new row of Theta.
    + $z_3$ equals the product of $a_2$ and $\Theta_2$
    + $a_3$ is the result of passing $z_3$ through $g()$

__Cost Function, non-regularized__:

3. Compute the unregularized cost according to ex4.pdf (top of Page 5), using $a_3$, your `y_matrix`, and `m` (the number of training examples). Note that the `h` argument inside the `log()` function is exactly `a3`. Cost should be a scalar value. Since `y_matrix` and `a3` are both matrices, you need to compute the double-sum.

    Remember to use element-wise multiplication with the `log()` function. For a discussion of why you can't (easily) use matrix multiplication here, see [this thread](https://www.coursera.org/learn/machine-learning/discussions/weeks/5/threads/ag_zHUGDEeaXnBKVQldqyw)

    Also, we're using the natural log, not `log10()`.

    Now you can run ex4.m to check the unregularized cost is correct, then you can submit this portion to the grader.

__Cost Regularization__:

4. Compute the regularized component of the cost according to ex4.pdf Page 6, using $\Theta_1$ and $\Theta_2$ (excluding the Theta columns for the bias units), along with $\lambda$, and $m$. The easiest method to do this is to compute the regularization terms separately, then add them to the unregularized cost from Step 3.

    You can run ex4.m to check the regularized cost, then you can submit this portion to the grader.

-----------------------

__Appendix:__

Here are the sizes for the Ex4 character recognition example, using the method described in this tutorial.

NOTE: The submit grader (and the gradient checking process) uses a different test case; these sizes are NOT for the submit grader or for gradient checking.

+ a1: 5000x401
+ z2: 5000x25
+ a2: 5000x26
+ a3: 5000x10
+ d3: 5000x10
+ d2: 5000x25
+ Theta1, Delta1 and Theta1_grad: 25x401
+ Theta2, Delta2 and Theta2_grad: 10x26

Here is a link to the test cases, so you can check [your work](https://www.coursera.org/learn/machine-learning/discussions/iyd75Nz_EeWBhgpcuSIffw)

The test cases for ex4 include the values of the internal variables discussed in the tutorial.


keywords: ex4 tutorial nncostfunction forward propagation


### [FAQ for Week 5 and programming exercise 4](https://www.coursera.org/learn/machine-learning/discussions/weeks/5/threads/ag_zHUGDEeaXnBKVQldqyw)


#### VIDEO LECTURE FAQ

There are a LOT of errors in the Week 5 video lectures. The Resources menu has a list of them in the Errata section. Do yourself a favor and keep the Errata list handy while you are watching the videos.

Lecture Notes are available in the Resources menu.

The lecture slides are now available in the "Review" section of each week's course materials.

Regarding the "Backpropagation Intuition" video

This video gives an intuitive presentation of backpropagation for students who were confused by the "Backpropagation Algorithm" video. The method given in this video is just an intuition - it is not mathematically valid, and it cannot be used for an implementation. Do not try to use the equations that are presented in this video.

Many of the Mentors recommend you ignore this video entirely. It creates lots of confusion and very little knowledge.


#### QUIZ FAQ

(empty)


#### PROGRAMMING EXERCISE FAQ

Note: Tutorials and additional Test Cases are available in the Resources menu.

ex4 is the most challenging programming exercise in the course.

I strongly recommend you read the tutorial for ex4 via the "Resources" menu. This tutorial provides the vectorized method, which has a couple of significant advantages over the iterative for-loop method Prof Ng lectures about and discusses in ex4.pdf:

+ The vectorized method is far easier to implement. It consists almost entirely of matrix multiplication. There are very few matrix indexes to worry about.
+ The vectorized method runs 30x to 50x faster than the for-loop method.


__Q1) My gradient checking results are wrong. How can I fix it?__

The key point to remember about backpropagation is that the hidden layer bias unit does not connect back to the input layer. So we do not include the first column of Theta2 in the backpropagation calculations that lead to Delta1 and Theta1_grad.

Here are some common reasons for this issue:

+ You have only excluded the first element of Theta2 from backpropagation into Theta1, instead of excluding all of the first column.
+ You have artificially added some rows or columns to Theta2 in order to force the dimensions to be correct. This is a bad thing - the only items to add are the bias units for a1 and a2 in forward propagation.
+ You are including the bias unit when you compute the sigmoid() or sigmoidGradient(). This is a bad thing.
+ In backpropagation, you are computing the sigmoidGradient() of a2, rather than z2. See Q2) below.


__Q2) What is the correct way to compute the sigmoid gradient?__

The sigmoid gradient should be computed using z2, not a2. This is a confusing point in the lectures.

`g'(z)` is not equal to `a.*(1-a)`. It is more correct to say that:

```matlab
g'(z) = g(z) .* (1 - g(z));
```

Since the cost function already has to compute g(z2), it is more efficient to save this result and compute `g(z2) .* (1-g(z2))` for use during backpropagation. If you instead call the sigmoidGradient() function, it will call `sigmoid()` again, which you have already computed during forward propagation.

__Q3) Why can't I use matrix multiplication in computing the cost `J`? Using vector math worked fine for logistic regression. Why doesn't it work for the NN?__

See this thread, it discusses the topic and includes a [worked-out example of the issue](https://www.coursera.org/learn/machine-learning/discussions/all/threads/AzIrrO7wEeaV3gonaJwAFA)

__Q4) Why is my NN training accuracy about 30%, even though my code passes the grader?__

Check if you implemented the function that randomly initializes the Theta matrices.

__Q5) Backpropagation - Step 3 on page 9 of ex4.pdf doesn't work - the dimensions don't match.__

The instructions for Step 3 and Step 4 are incomplete. There are two ways to implement this:

a) In Step 3, if you compute the sigmoid gradient of z2, then you must remove the first column of Theta2 when you compute $\delta^{(2)}$.

...or...

b) In Step 3, if you compute the sigmoid gradient as $a2 .\ast (1 - a2)$, then you must pay attention to the note about removing the first column of $\delta^{(2)}$ when you compute $\Delta^{(1)}$.


### [Computing the NN cost J using the matrix product](https://www.coursera.org/learn/machine-learning/discussions/all/threads/AzIrrO7wEeaV3gonaJwAFA)

Students often ask why they can't use matrix multiplication to compute the cost value J in the Neural Network cost function. This post explains why.

Short answer: You can use matrix multiplication, but it is tricky.

Here is the equation for the unregularized cost `J`:

$$J(\theta) = -\dfrac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \left[ y^{(i)} \log((h_\theta(x^{(i)}))_k) - (1 - y^{(i)}) \log((1 - h_\theta(x^{(i)}))_k) \right]$$

Notice the double-sum. `i` ranges over the training examples `m`, and `k` ranges over the output labels `K`. The cost has two parts - the first involves the product of `y` and `log(h)`, and the second involves the product of `(1-y)` and `log(1-h)`. Note that `y` and `h` are both matrices of size $(m \times K$), and the multiplication in the cost equation is an element-wise scalar product for each element in the matrices.

Recall that for linear and logistic regression, `y` and `h` were both vectors, so we could compute the sum of their products easily using vector multiplication. After transposing one of the vectors, we get a result of size $(1 \times m) * (m \times 1)$. That's a scalar value. So that worked fine, as long as `y` and `h` are vectors.

But the when `h` and `y` are matrices, the same trick does not work as easily. Here's why.

Let's first show the math using the element-wise product of two matrices A and B. For simplicity, let's use $m= 3$ and $K=2$.


$$A = \begin{bmatrix} a & b \\ c & d \\ e & f \end{bmatrix}, \quad B = \begin{bmatrix} m & n \\ o & p \\ q & r \end{bmatrix}$$

The sum over the rows and columns of the element-wise product is:

$$\sum \sum A .\ast B = am + bn + co + dp + eq + fr$$

Now let's detail the math for this using a matrix product. Since `A` and `B` are the same size, but the number of rows and columns are not the same, we must transpose one of the matrices before we compute the product. Let's transpose the `A` matrix, so the product matrix will be size $(K \times K)$. We could of course invert the `B` matrix, but then the product matrix would be size $(m \times m)$. The $(m \times m)$ matrix is probably a lot larger than $(K \times K)$.

It turns out (and is left for the reader to prove) that both the $(m \times m)$ and $(K \times K)$ matrices will give the same results for the cost J.

$$ A′ \ast B = \begin{bmatrix} a & c & e \\ b & d & f \end{bmatrix}\ast \begin{bmatrix} m & n \\ o & p \\ q & r \end{bmatrix}$$

After the matrix product, we get:

$$A^\prime\ast B = \begin{bmatrix} (am+co+eq) & (an+cp+er) \\ (bm+do+fq) & (bn+dp+fr) \end{bmatrix}$$

So this is a size $(K \times K)$ result, as expected. Note that the terms which lie on the main diagonal are the same terms that result from the double-sum of the element-wise product. The next step is to compute the sum of the diagonal elements using the `trace()` command, or by `sum(sum(...))` after element-wise multiplying by an identity matrix of size $(K \times K)$.

The sum-of-product terms that are NOT on the main diagonal are unwanted - they are not part of the cost calculation. So simply using `sum(sum(...))` over the matrix product will include these terms, and you will get an incorrect cost value.

The performance of each of these methods - double-sum of the element-wise product, or the matrix product with either `trace()` or the sum of the diagonal elements - should be evaluated, and the best one used for a given data set.


### [Cost Function](https://www.coursera.org/learn/machine-learning/programming/AiHgN/neural-network-learning/discussions/threads/-umzc7taEeeb_xL-a3Jo7A)

Second the motion. Check out the [FAQ](https://www.coursera.org/learn/machine-learning/discussions/weeks/5/threads/ag_zHUGDEeaXnBKVQldqyw) (in this Forum), the general [tips from mentors](https://www.coursera.org/learn/machine-learning/supplement/SFKpu/tips-from-mentors), the [tutorial](https://www.coursera.org/learn/machine-learning/discussions/all/threads/m0ZdvjSrEeWddiIAC9pDDA), and the [lecture](https://www.coursera.org/learn/machine-learning/resources/EcbzQ) and [programming notes](https://www.coursera.org/learn/machine-learning/resources/Uuxg6) for week 5 (in the Resources section). They contain hints on vectorizing the solution. The [test cases](https://www.coursera.org/learn/machine-learning/discussions/all/threads/0SxufTSrEeWPACIACw4G5w) are helpful for debugging. Be sure to check the [errata](https://www.coursera.org/learn/machine-learning/resources/go98N).

The algorithm discussed in the lectures is not vectorized, uses multiple for loops and is very slow. Using it is __not__ recommended.

The results of the Logistic Regression cost function should always be positive. Note that logarithms of numbers between 0 and 1 are always negative, and that sign is cancelled by the initial negative sign since y can only be 0 or 1.

I suggest you double check the values you're feeding to your logarithms, your y_matrix, and the internal variables provided in the test case.






