# Programming Exercise 1: Linear Regression

[Program Assignment](https://s3.amazonaws.com/spark-public/ml/exercises/on-demand/machine-learning-ex1.zip)

## Simple Octave/MATLAB function

The first part of ex1.m gives you practice with Octave/MATLAB syntax and the homework submission process. In the le warmUpExercise.m, you will nd the outline of an Octave/MATLAB function. Modify it to return a 5 x 5 identity matrix by filling in the following code:

```matlab
A = eye(5);
```

After completing a part of the exercise, you can submit your solutions for grading by typing submit at the Octave/MATLAB command line.


## Linear regression with one variable

The file `ex1data1.txt` contains the dataset for our linear regression problem. The rst column is the population of a city and the second column is the prot of a food truck in that city. A negative value for prot indicates a loss.

### Plotting the Data

In `ex1.m` the dataset is loaded from the data le into the variables $X$ and $y$:

```matlab
data = load('ex1data1.txt'); % read comma separated data
X = data(:, 1); y = data(:, 2);
m = length(y); % number of training examples
```

Next, the script calls the `plotData` function to create a scatter plot of the data. Your job is to complete `plotData.m` to draw the plot; modify the fille and fill in the following code:

```matlab
plot(x, y, 'rx', 'MarkerSize', 10); % Plot the data
ylabel('Profit in $10,000s'); % Set the y􀀀axis label
xlabel('Population of City in 10,000s'); % Set the x􀀀axis label
```

### Gradient Descent

#### Update Equations (Derivation)

Dataset: $m$ samples and $n$ features

Cost function:

$$J(\theta) = \dfrac{1}{2m} \sum_{i=1}^m (h_\theta (x^{(i)}) - y^{(i)})^2$$

Hypothesis $h_\theta(x)$ is given by the linear model

$$h_\theta (x) = \theta^T x = \theta_0 + \theta_1 x_1$$

Objective:

$$\displaystyle \min_\theta J(\theta)$$


Batch gradient descent for each iteration

$$\theta_j := \theta_j - \alpha \dfrac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}$$
<span style="text-align: center; padding-top: 0.5em;padding-left: calc(50vw - 5em);"> (simultaneously update </span>
$\; \theta_j, \;\; \forall j$)<br/>


Notations:

$$X = \begin{bmatrix} x_0^{(1)} & x_1^{(1)} & \cdots & x_n^{(1)} \\
x_0^{(2)} & x_1^{(2)} & \cdots & x_n^{(2)} \\
\vdots & \vdots & \ddots & \vdots \\
x_0^{(m)} & x_1^{(m)} & \cdots & x_n^{(m)}
\end{bmatrix} = \begin{bmatrix} x^{(1)} \\ x^{(2)} \\ \vdots \\ x^{(m)} \end{bmatrix}\quad\quad\quad
\vec{y} = \begin{bmatrix} y^{(0)} \\ y^{(2)} \\ \vdots \\ y^{(m)}  \end{bmatrix} \quad\quad\quad
\vec{\theta} = \begin{bmatrix} \theta_0 \\ \theta_1 \\ \vdots \\ \theta_m \end{bmatrix}
$$
<br/>

Vectorization of Hypothesis Function

$$\begin{array}{rcl}
h_\theta (x^{(i)}) & = & \theta_0 x_0^{(i)} + \theta_1 x_1^{(i)} + \cdots + \theta_n x_n^{(i)} \\\\
h_\theta (X) & = & \begin{bmatrix} h_\theta(x^{(1)}) \\ h_\theta(x^{(2)}) \\ \vdots \\ h_\theta(x^{(m)}) \end{bmatrix} = 
\begin{bmatrix} \theta_0 x_0^{(1)} + \theta_1 x_1^{(1)} + \cdots + \theta_n x_n^{(1)} \\ \theta_0 x_0^{(2)} + \theta_1 x_1^{(2)} + \cdots + \theta_n x_n^{(2)} \\ \vdots \\ \theta_0 x_0^{(m)} + \theta_1 x_1^{(m)} + \cdots + \theta_n x_n^{(m)} \end{bmatrix} = \begin{bmatrix} x_0^{(1)} & x_1^{(1)} & \cdots & x_n^{(1)} \\ x_0^{(1)} & x_1^{(2)} & \cdots & x_n^{(2)}  \\ \vdots & \vdots & \ddots & \vdots \\ x_0^{(m)} & x_1^{(m)} & \cdots & x_n^{(m)} \end{bmatrix} 
\begin{bmatrix} \theta_0 \\ \theta_1 \\ \vdots \\ \theta_n \end{bmatrix} = X \vec{\theta}
\end{array}$$

Vectorization for Cost function

$$\begin{array}{rcl}
J(\vec{\theta}) & = & \dfrac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 \\\\ & = & \dfrac{1}{2m} \begin{bmatrix} h_\theta(x^{(1)}) - y^{(1)} & h_\theta(x^{(2)}) - y^{(2)} & \cdots & h_\theta(x^{(m)}) - y^{(m)} \end{bmatrix}  \begin{bmatrix} h_\theta(x^{(1)}) - y^{(1)} \\ h_\theta(x^{(2)}) - y^{(2)} \\ \vdots \\ h_\theta(x^{(m)}) - y^{(m)} \end{bmatrix} \\\\ & = & \dfrac{1}{2m} \begin{bmatrix} h_\theta(x^{(1)}) - y^{(1)} \\ h_\theta(x^{(2)}) - y^{(2)} \\ \vdots \\ h_\theta(x^{(m)}) - y^{(m)} \end{bmatrix}^T \begin{bmatrix} h_\theta(x^{(1)}) - y^{(1)} \\ h_\theta(x^{(2)}) - y^{(2)} \\ \vdots \\ h_\theta(x^{(m)}) - y^{(m)} \end{bmatrix} \\ \\ & = & \dfrac{1}{2m} \left( \begin{bmatrix} h_\theta(x^{(1)}) \\ h_\theta(x^{(2)}) \\ \vdots \\ h_\theta(x^{(m)})\end{bmatrix} - \begin{bmatrix} y^{(1)} \\ y^{(2)} \\ \vdots \\ y^{(m)} \end{bmatrix} \right)^T \left( \begin{bmatrix} h_\theta(x^{(1)}) \\ h_\theta(x^{(2)}) \\ \vdots \\ h_\theta(x^{(m)})\end{bmatrix} - \begin{bmatrix} y^{(1)} \\ y^{(2)} \\ \vdots \\ y^{(m)} \end{bmatrix} \right) \\\\ & = & \dfrac{1}{2m} (X\vec{\theta} - \vec{y})^T (X\vec{\theta} - \vec{y}) \end{array}$$


Vectorization for Batch Gradient Descent

$$\begin{array}{rcl} \vec{\theta} & := & \vec{\theta} - \alpha \dfrac{1}{m} \begin{bmatrix} \sum_{i=1}^m (h_\theta (x^{(i)} - y^{(i)}) x_0^{(i)} \\\\ \sum_{i=1}^m (h_\theta (x^{(i)} - y^{(i)}) x_1^{(i)} \\ \vdots \\ \sum_{i=1}^m (h_\theta (x^{(m)} - y^{(m)}) x_1^{(m)} \end{bmatrix} = \vec{\theta} - \dfrac{\alpha}{m} \begin{bmatrix} \sum_{i=1}^m h_\theta (x^{(i)} \cdot x_0^{(i)} - \sum_{i=1}^m y^{(i)}) \cdot x_0^{(i)} \\\\  \sum_{i=1}^m h_\theta (x^{(i)} \cdot x_1^{(i)} - \sum_{i=1}^m y^{(i)}) \cdot x_1^{(i)} \\ \vdots \\ \sum_{i=1}^m h_\theta (x^{(i)} \cdot x_m^{(i)} - \sum_{i=1}^m y^{(i)}) \cdot x_m^{(i)} \end{bmatrix} \\\\ & = & \vec{\theta} - \dfrac{\alpha}{m} \left( \underbrace{\begin{bmatrix} \sum_{i=1}^m h_\theta (x^{(i)} \cdot x_0^{(i)} \\\\ \sum_{i=1}^m h_\theta (x^{(i)} \cdot x_1^{(i)} \\ \vdots \\ \sum_{i=1}^m h_\theta (x^{(i)} \cdot x_m^{(i)}  \end{bmatrix}}_{(A)} - \underbrace{\begin{bmatrix} \sum_{i=1}^m y^{(i)}) \cdot x_0^{(i)} \\\\ \sum_{i=1}^m y^{(i)}) \cdot x_1^{(i)} \\ vdots \\ \sum_{i=1}^m y^{(i)}) \cdot x_m^{(i)}  \end{bmatrix}}_{(B)} \right)
\end{array}$$

Part (A) with $j$

$$\begin{array}{rcl} \displaystyle \sum_{i=1}^m h_\theta(x^{(i)}) \cdot x_j^{(i)} & = &h_\theta(x^{(1)}) x_0^{(1)} + h_\theta(x^{(2)}) x_j^{(2)} + \cdots + h_\theta(x^{(n)}) x_j^{(n)} \\\\ & = & \begin{bmatrix} x_j^{(1)} & x_j^{(2)} & \cdots & x_j^{(m)}\end{bmatrix} \begin{bmatrix} h_\theta(x^{(1)}) \\ h_\theta(x^{(2)}) \\ \vdots \\ h_\theta(x^{(m)}) \end{bmatrix}  \\ & = & \begin{bmatrix} x_j^{(1)} & x_j^{(2)} & \cdots & x_j^{(m)}\end{bmatrix} h_\theta(X) = \begin{bmatrix} x_j^{(1)} & x_j^{(2)} & \cdots & x_j^{(m)} \end{bmatrix} X\vec{\theta} \end{array}$$

Part (A) $\;\forall j$

$$\begin{bmatrix} \sum_{i=1}^m h_\theta (x^{(i)} \cdot x_0^{(i)} \\\\ \sum_{i=1}^m h_\theta (x^{(i)} \cdot x_1^{(i)} \\ \vdots \\ \sum_{i=1}^m h_\theta (x^{(i)} \cdot x_m^{(i)}  \end{bmatrix} = \begin{bmatrix} x_0^{(1)} & x_0^{(2)} & \cdots & x_0^{(m)} \\ x_1^{(1)} & x_1^{(2)} & \cdots & x_1^{(m)} \\ \vdots & \vdots & \ddots & \vdots \\ x_j^{(1)} & x_j^{(2)} & \cdots & x_j^{(m)} \end{bmatrix} h_\theta(X) = X^TX\vec{\theta}$$

Part (B) for $j$

$$\begin{array}{rcl} \sum_{i=1}^m y^{(i)} x_j^{(i)} & = & x_j^{(1)} y^{(1)} + x_j^{(2)} y^{(2)} + \cdots + x_j^{(m)} y^{(m)} \\\\ & = & \begin{bmatrix} x_j^{(1)} & x_j^{(2)} & \cdots & x_j^{(m)} \end{bmatrix} \begin{bmatrix} y^{(1)} \\ y^{(2)} \\ \vdots \\ y^{(m)} \end{bmatrix} = \begin{bmatrix} x_j^{(1)} & x_j^{(2)} & \cdots & x_j^{(m)} \end{bmatrix} \vec{y}
\end{array}$$


Part (B) $\;\forall j$

$$\begin{bmatrix} \sum_{i=1}^m y^{(i)}) \cdot x_0^{(i)} \\\\ \sum_{i=1}^m y^{(i)}) \cdot x_1^{(i)} \\ \vdots \\ \sum_{i=1}^m y^{(i)}) \cdot x_m^{(i)}  \end{bmatrix} = \begin{bmatrix} x_0^{(1)} & x_0^{(2)} & \cdots & x_0^{(m)} \\ x_1^{(1)} & x_1^{(2)} & \cdots & x_1^{(m)} \\ \vdots & \vdots & \ddots & \vdots \\ x_j^{(1)} & x_j^{(2)} & \cdots & x_j^{(m)} \end{bmatrix} \vec{y} = X^T \vec{y}$$

Therefore, the batch gradient descent iteration can be obtained with

$$\vec{\theta} := \vec{\theta} - \alpha \dfrac{1}{m} \begin{bmatrix} \sum_{i=1}^m (h_\theta (x^{(i)} - y^{(i)}) x_0^{(i)} \\\\ \sum_{i=1}^m (h_\theta (x^{(i)} - y^{(i)}) x_1^{(i)} \\ \vdots \\ \sum_{i=1}^m (h_\theta (x^{(m)} - y^{(m)}) x_1^{(m)} \end{bmatrix} = \vec{\theta} - \dfrac{\alpha}{m} (X^TX\vec{\theta} - X^T\vec{Y}) = \vec{\theta} - \dfrac{\alpha}{m} X^T (X\vec{\theta} - \vec{y})$$

#### Implementation

+ Add another dimension to our data to accommodate the $\theta_0$ intercept term
+ Initialize the initial parameters to $\theta$ and the learning rate alpha to $0.01$.

    ```matlab
    X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
    theta = zeros(2, 1); % initialize fitting parameters

    iterations = 1500;
    alpha = 0.01;
    ```

#### Computing the cost $J(\vec{\theta})$

+ implement a function to calculate $J(\vec{\theta})$
+ complete the code in the file `computeCost.m`, which is a function that computes $J(\vec{\theta})$
+ expect to see a cost of `32.07`

    ```matlab
    J = (X * theta - y)' * (X * theta - y) / (2*m);
    ```

#### Gradient descent

+ implement gradient descent in the fille `gradientDescent.m`
+ supply the updates to $\theta$ within each iteration
+ the cost $J(\vec{\theta})$ is parameterized by the vector $\vec{\theta}$, not $X$ and $\vec{y}$. i.e., minimize the value of  $J(\vec{\theta})$ by changing the values of the vector $\vec{\theta}$, not by changing $X$ or $\vec{y}$
+ to verify that gradient descent is working correctly is to look at the value of $J(\vec{\theta})$ and check that it is decreasing with each step
+ final values for $\vec{\theta}$ will also be used to make predictions on prots in areas of 35,000 and 70,000 people

    ```matlab
    for iter = 1:num_iters

        % ====================== YOUR CODE HERE ======================
        % Instructions: Perform a single gradient step on the parameter vector
        %               theta. 
        %
        % Hint: While debugging, it can be useful to print out the values
        %       of the cost function (computeCost) and gradient here.
        %

        theta = theta - alpha/m * X' * (X * theta - y)

        % ============================================================

        % Save the cost J in every iteration    
        J_history(iter) = computeCost(X, y, theta);

    end
    ```

    ```matlab
    predict1 = [1, 3.5] * theta;
    predict2 = [1, 7] * theta;
    ```


### Debugging

gradient descent:
+ Octave/MATLAB array indices start from one, not zero.
+ inspect your matrix operations to make sure that you're adding and multiplying matrices of compatible dimensions
+ By default, Octave/MATLAB interprets math operators to be matrix operators.
+ Element-wise operation: add the "dot" notation to specify this to Octave/MATLAB.


## Visualizing $J(\vec{\theta})$

+ plot the cost over a 2-dimensional grid of $\theta_0$ and $\theta_1$ values.
+ calculate $J(\vec{\theta})$ over a grid of values using the computeCost function

    ```matlab
    % initialize J vals to a matrix of 0's
    J vals = zeros(length(theta0 vals), length(theta1 vals));

    % Fill out J vals
    for i = 1:length(theta0 vals)
        for j = 1:length(theta1 vals)
            t = [theta0 vals(i); theta1 vals(j)];
            J vals(i,j) = computeCost(x, y, t);
        end
    end
    ```


## Linear regression with multiple variables

+ implement linear regression with multiple variables to predict the prices of houses
+ file `ex1data2.txt` contains a training set of housing prices in Portland, Oregon
    + the rst column is the size of the house (in square feet)
    + the second column is the number of bedrooms
    + the third column is the price of the house
+ The `ex1 multi.m` script has been set up to help you step through this exercise


### Feature Normalization

+ complete the code in featureNormalize.m to
    + Subtract the mean value of each feature from the dataset.
    + After subtracting the mean, additionally scale (divide) the feature values by their respective \standard deviations."
+ In Octave/MATLAB, you can use the `std` function to compute the standard deviation.
+ inside `featureNormalize.m`, the quantity `X(:,1)` contains all the values of x1 (house sizes) in the training set, so `std(X(:,1))` computes the standard deviation of the house sizes. 
+ At the time that `featureNormalize.m` is called, the extra column of 1's corresponding to `x0 = 1` has not yet been added to `X` (see ex1 multi.m for details).
+ Implementation Note:
    + When normalizing the features, it is important to store the values used for normalization - the mean value and the standard deviation used for the computations.
    + Given a new $x$ value (living room area and number of bedrooms), we must first normalize $x$ using the mean and standard deviation that we had previously computed from the training set.
    + After learning the parameters from the model, we often want to predict the prices of houses we have not seen before.

    ```matlab
    [m, n] = size(X);

    mu = mean(X);
    sigma = std(X);

    for iter = 1:m,
        X_norm(iter, :) = (X_norm(iter, :) - mu) ./ sigma;
    end;

    % Estimate the price of a 1650 sq-ft, 3 br house
    % ====================== YOUR CODE HERE ======================
    % Recall that the first column of X is all-ones. Thus, it does
    % not need to be normalized.

    price = [1, ([1650 3] - mu) ./ sigma] * theta; % You should change this
    ```


### Gradient Descent

Cost function in vectorized form

$$J(\theta) = \dfrac{1}{2m} (X\theta - \vec{y})^T(X\theta - \vec{y})$$

<br/>

$$\quad\quad X = \begin{bmatrix} --- & (x^{(1)})^T & --- \\ --- & (x^{(2)})^T & --- \\ & \vdots & \\ --- & (x^{(m)})^T & --- \end{bmatrix} \quad\quad \vec{y} = \begin{bmatrix} y^{(1)} \\ y^{(2)} \\ \vdots \\ y^{(m)} \end{bmatrix}$$

#### Selecting learning rate

+ change the learning rate by modifying `ex1 multi.m` and changing the part of the code that sets the learning rate
+ call `gradientDescent.m` function and run gradient descent for about 50 iterations at the chosen learning rate
+ return the history of J() values in a vector $J$
+ plots the J values against the number of the iterations
+ trying values of the learning rate $\alpha$ on a log-scale, at multiplicative steps of about 3 times the previous value (i.e., 0.3, 0.1, 0.03, 0.01 and so on).


### Normal Equations



