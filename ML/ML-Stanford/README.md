# Machine Learning

## Welcome

+ [Welcome to Machine Learning!](00-Welcome.md#welcome-to-machine-learning)
+ [Machine Learning Honor Code](00-Welcome.md#machine-learning-honor-code)
    + [Machine Learning Honor Code](00-Welcome.md#machine-learning-honor-code-1)
    + [Guidelines for Posting Code in Discussion Forums](00-Welcome.md#guidelines-for-posting-code-in-discussion-forums)
+ [How to Use Discussion Forums](00-Welcome.md#how-to-use-discussion-forums)
    + [Report Abuse](00-Welcome.md#report-abuse)
    + [Following](00-Welcome.md#following)
    + [Improving Your Posts](00-Welcome.md#improving-your-posts)
+ [Resources](00-Welcome.md#resources)
    + [Tutorials](00-Welcome.md#tutorials)
        + [ex1](00-Welcome.md#ex1)
        + [ex2](00-Welcome.md#ex2)
        + [ex3](00-Welcome.md#ex3)
        + [ex4](00-Welcome.md#ex4)
        + [ex5](00-Welcome.md#ex5)
        + [ex6](00-Welcome.md#ex6)
        + [ex7](00-Welcome.md#ex7)
        + [ex8](00-Welcome.md#ex8)
    + [Test Cases](00-Welcome.md#test-cases)
    + [Useful Resources](00-Welcome.md#useful-resources)
    + [Online E-Books](00-Welcome.md#online-e-books)
    + [Boosting](00-Welcome.md#boosting)
    + [Tips on Octave OS X](00-Welcome.md#tips-on-octave-os-x)
+ [Who are Mentors?](00-Welcome.md#who-are-mentors)
+ [Get to Know Your Classmates](00-Welcome.md#get-to-know-your-classmates)
+ [Frequently Asked Questions](00-Welcome.md#frequently-asked-questions)
+ [Programming Environment](00-Welcome.md#programming-environment)
    + [Environment Setup Instructions](00-Welcome.md#environment-setup-instructions)
    + [Setting Up Your Programming Assignment Environment](00-Welcome.md#setting-up-your-programming-assignment-environment)
    + [Access MATLAB Online and Upload the Exercise Files](00-Welcome.md#access-matlab-online-and-upload-the-exercise-files)
    + [Installing Octave on Windows](00-Welcome.md#installing-octave-on-windows)
    + [Installing Octave on Mac OS X (10.10 Yosemite and 10.9 Mavericks and Later)](00-Welcome.md#installing-octave-on-mac-os-x-1010-yosemite-and-109-mavericks-and-later)
    + [Installing Octave on Mac OS X (10.8 Mountain Lion and Earlier)](00-Welcome.md#installing-octave-on-mac-os-x-108-mountain-lion-and-earlier)
    + [Installing Octave on GNU/Linux](00-Welcome.md#installing-octave-on-gnulinux)
    + [More Octave/MATLAB resources](00-Welcome.md#more-octavematlab-resources)
+ [Submitting Programming Assignments](00-Welcome.md#submitting-programming-assignments)
    + [Working on and Submitting Programming Assignments](00-Welcome.md#working-on-and-submitting-programming-assignments)
    + [Programming tips from Mentors](00-Welcome.md#programming-tips-from-mentors)
    + [Programming Exercise Tutorials (list)](00-Elecome.md#programming-exercisetutorials-list)


## Introduction

+ [Welcome](01-Intro.md#lecture-notes)
+ [What is Machine Learning?](01-Intro.md#what-is-machine-learning)
+ [Supervised Learning](01-Intro.md#supervised-learning)
+ [Unsupervised Learning](01-Intro.md#unsupervised-learning)
+ [Review](01-Intro.md#review)
    + [Lecture Slides](01-Intro.md#lecture-slides)
    + [Errata](01-Intro.md#errata)
+ [Quiz: Introduction](01-Intro.md#quiz-introduction)


## Linear Regression with One Variable

+ [Model and Cost Function](02-ModelCost.md#model-representation)
    + [Model Representation](02-ModelCost.md#cost-function)
    + [Cost Function](02-ModelCost.md#)
    + [Cost Function - Intuition I](02-ModelCost.md#cost-function---intuition-i)
    + [Cost Function - Intuition II](02-ModelCost.md#cost-function---intuition-ii)
+ [Parameter Learning](02-ModelCost.md#parameter-learning)
    + [Gradient Descent](02-ModelCost.md#gradient-descent)
    + [Gradient Descent Intuition](02-ModelCost.md#gradient-descent-intuition)
    + [Gradient Descent For Linear Regression](02-ModelCost.md#gradient-descent-for-linear-regression)
+ [Review](02-ModelCost.md#review)
    + [Lecture Slides](02-ModelCost.md#lecture-slides)
    + [Errata](02-ModelCost.md#errata)
+ [Quiz: Linear Regression with One Variable](02-ModelCost.md#quiz-linear-regression-with-one-variable)


## Linear Algebra Review

+ [Matrices and Vectors](03-LAlgebra.md#matrices-and-vectors)
+ [Addition and Scalar Multiplication](03-LAlgebra.md#addition-and-scalar-multiplication)
+ [Matrix Vector Multiplication](03-LAlgebra.md#matrix-vector-multiplication)
+ [Matrix Matrix Multiplication](03-LAlgebra.md#matrix-matrix-multiplication)
+ [Matrix Multiplication Properties](03-LAlgebra.md#matrix-multiplication-properties)
+ [Inverse and Transpose](03-LAlgebra.md#inverse-and-transpose)
+ [Review](03-LAlgebra.md#review)
    + [Lecture Slides](03-LAlgebra.md#lecture-slides)
    + [Errata](03-LAlgebra.md#errata)
+ [Practice Quiz: Linear Algebra](03-LAlgebra.md#practice-quiz-linear-algebra)



## Linear Regression with Multiple Variables

+ [Multivariate Linear Regression](04-LRegMVar.md#multivariate-linear-regression)
    + [Multiple Features](04-LRegMVar.md#multiple-features)
    + [Gradient Descent for Multiple ](04-LRegMVar.md#gradient-descent-for-multiple)
    + [Gradient Descent in Practice I - Feature ](04-LRegMVar.md#gradient-descent-in-practice-i---feature)
    + [Gradient Descent in Practice II - Learning Rate](04-LRegMVar.md#gradient-descent-in-practice-ii---learning-rate)
    + [Features and Polynomial Regression](04-LRegMVar.md#features-and-polynomial-regression)
+ [Computing Parameters Analytically](04-LRegMVar.md#computing-parameters-analytically)
    + [Normal Equation](04-LRegMVar.md#normal-equation)
    + [Normal Equation Noninvertibility](04-LRegMVar.md#normal-equation-noninvertibility)
+ [Review](04-LRegMVar.md#review)
    + [Lecture Slides](04-LRegMVar.md#lecture-slides)
    + [Errata](04-LRegMVar.md#errors-in-the-video-lectures)
+ [Quiz: Linear Regression with Multiple Variables](04-LRegMVar.md#quiz-linear-regression-with-multiple-variables)

## Octave/Matlab Tutorial

+ [Basic Operations](05-Octave.md#basic-operations)
+ [Moving Data Around](05-Octave.md#moving-data-around)
+ [Computing on Data](05-Octave.md#computing-on-data)
+ [Plotting Data](05-Octave.md#plotting-data)
+ [Control Statements: for, while, if statement](05-Octave.md#control-statements-for-while-if-statement)
+ [Vectorization](05-Octave.md#vectorization)
+ [Review](05-Octave.md#review)
    + [Lecture Slides](05-Octave.md#lecture-slides)
    + [Errata](05-Octave.md#errata)
    + [Quiz: Octave/Matlab Tutorial](05-Octave.md#quiz-octavematlab-tutorial)


## Programming Assignment 1: Linear Regression

## Logistic Regression

+ [Classification and Representation](06-Logistic.md#classification-and-representation)
    + [Classification](06-Logistic.md#classification)
    + [Hypothesis Representation](06-Logistic.md#hypothesis-representation)
    + [Decision Boundary](06-Logistic.md#decision-boundary)
+ [Logistic Regression Model](06-Logistic.md#logistic-regression-model)
    + [Cost Function](06-Logistic.md#cost-function)
    + [Simplified Cost Function and Gradient Descent](06-Logistic.md#simplified-cost-function-and-gradient-descent)
    + [Advanced Optimization](06-Logistic.md#advanced-optimization)
+ [Multiclass Classification: One-vs-all](06-Logistic.md#multiclass-classification-one-vs-all)
+ [Review](06-Logistic.md#review)
    + [Lecture Slides](06-Logistic.md#lecture-slides)
    + [Errata](06-Logistic.md#errata)
    + [Quiz: Logistic Regression](06-Logistic.md#quiz-logistic-regression)


## Regularization: Solving the Problem of Overfitting

+ [The Problem of Overfitting](07-Overfit.md#the-problem-of-overfitting)
+ [Cost Function](07-Overfit.md#cost-function)
+ [Regularized Linear Regression](07-Overfit.md#regularized-linear-regression)
+ [Regularized Logistic Regression](07-Overfit.md#regularized-logistic-regression)
+ [Review](07-Overfit.md#review)
    + [Lecture Slides](07-Overfit.md#lecture-slides)
    + [Errata]()(07-Overfit.md#errata)
    + [Quiz: Regularization](07-Overfit.md#quiz-regularization)



## Programming Assignment: Logistic Regression

+ [Logistic Regression](ex02.md#logistic-regression)
    + [Visualizing the data](ex02.md#visualizing-the-data)
    + [Implementation](ex02.md#implementation)
+ [Regularized logistic regression](ex02.md#regularized-logistic-regression)
    + [Visualizing the data](ex02.md#visualizing-the-data-1)
    + [Feature mapping](ex02.md#feature-mapping)
    + [Cost function and gradient](ex02.md#cost-function-and-gradient)
    + [Plotting the decision boundary](ex02.md#plotting-the-decision-boundary)
    + [Optional exercises](ex02.md#optional-exercises)
+ [Programming Ex.2](ex02.md#programming-ex2)
    + [Gradient and theta values for ex2.m](ex02.md#gradient-and-theta-values-forex2m)
    + [mapFeature() discussion](ex02.md#mapfeature-discussion)
    + [plotData.m - color attributes](ex02.md#plotdatam---color-attributes)
    + [Logistic Regression Gradient](ex02.md#logistic-regression-gradient)
    + [Sigmoid function](ex02.md#sigmoid-function)
    + [Decision Boundary](ex02.md#decision-boundary)

## Neural Networks: Representation

+ [Motivations](08-NNRepres.md#motivations)
    + [Non-linear Hypotheses](08-NNRepres.md#non-linear-hypotheses)
    + [Neurons and the Brain](08-NNRepres.md#neurons-and-the-brain)
+ [Neural Networks](08-NNRepres.md#neural-networks)
    + [Model Representation I](08-NNRepres.md#model-representation-i)
    + [Model Representation II](08-NNRepres.md#model-representation-ii)
+ [Applications](08-NNRepres.md#applications)
    + [Examples and Intuitions I](08-NNRepres.md#examples-and-intuitions-i)
    + [Examples and Intuitions II](08-NNRepres.md#examples-and-intuitions-ii)
    + [Multiclass Classification](08-NNRepres.md#multiclass-classification)
+ [Review](08-NNRepres.md#review)
    + [Lecture Slides](08-NNRepres.md#lecture-slides)
    + [Errata](08-NNRepres.md#errata)
    + [Quiz: Neural Networks: Representation](08-NNRepres.md#quiz-neural-networks-representation)



## Programming Assignment: Multi-class Classification and Neural Networks

+ [Multi-class Classification](ex03.md#multi-class-classification)
    + [Dataset](ex03.md#dataset)
    + [Visualizing the data](ex03.md#visualizing-the-data)
    + [Vectorizing Logistic Regression](ex03.md#vectorizing-logistic-regression)
    + [One-vs-all Classification](ex03.md#one-vs-all-classification)
+ [Neural Networks](ex03.md#neural-networks)
    + [Model representation](ex03.md#model-representation)
    + [Feedforward Propagation and Prediction](ex03.md#feedforward-propagation-and-prediction)
+ [Debugging Tip](ex03.md#debugging-tip)
    + [1.4.1 One-vs-all Prediction](ex03.md#141-one-vs-all-prediction)
    + [2.2 Feedforward Propagation and Prediction (Neural network)](ex03.md#22-feedforward-propagation-and-prediction-neural-network)
    + [Prediction of an image outside the dataset (Neural Network)](ex03.md#prediction-of-an-image-outside-the-dataset-neural-network)


## Neural Networks: Learning

+ [Cost Function and Backpropagation](09-NNLearn.md#cost-function-and-backpropagation)
    + [Cost](09-NNLearn.md#cost-function)
    + [Backpropagation Algorithm](09-NNLearn.md#backpropagation-algorithm)
    + [Backpropagation Intuition](09-NNLearn.md#backpropagation-intuition)
+ [Backpropagation in Practice](09-NNLearn.md#backpropagation-in-practice)
    + [Implementation Note: Unrolling Parameters](09-NNLearn.md#implementation-note-unrolling-parameters)
    + [Gradient Checking](09-NNLearn.md#gradient-checking)
    + [Random Initialization](09-NNLearn.md#random-initialization)
    + [Putting It Together](09-NNLearn.md#putting-it-together)
+ [Application of Neural Networks-Autonomous Driving](09-NNLearn.md#application-of-neural-networks-autonomous-driving)
+ [Review](09-NNLearn.md#review)
    + [Lecture Slides](09-NNLearn.md#lecture-slides)
    + [Errata](09-NNLearn.md#errata)
    + [Quiz: Neural Networks: Learning](09-NNLearn.md#quiz-neural-networks-learning)



## Programming Assignment: Neural Network Learning

+ 1 [Neural Network](ex04.md#1-neural-network)
    + 1.1 [Visualizing the data](ex04.md#1-1-visualizing-the-data)
    + 1.2 [Model representation](ex04.md#1-2-model-representation)
    + 1.3 [Feedbackforward and cost function](ex04.md#1-3-feedbackforward-and-cost-function)
    + 1.4 [Regularized cost function](ex04.md#1-4-regularized-cost-function)
+ 2 [Backpropagation](ex04.md#2-backpropagation)
    + 2.1 [Sigmoid gradient](ex04.md#2-1-sigmoid-gradient)
    + 2.2 [Random initialization](ex04.md#2-2-random-initialization)
    + 2.3 [Backpropagation](ex04.md#2-3-backpropagation)
    + 2.4 [Gradient checking](ex04.md#2-4-gradient-checking)
    + 2.5 [Regularized Neural Networks](ex04.md#2-5-regularized-neural-networks)
    + 2.6 [Learning parameters using `fmincg`](ex04.md#2-6-learning-parameters-using-fmincg)
+ 3 [Visualizing the hidden layer](ex04.md#3-visualizing-the-hidden-layer)
    + 3.1 [Optional exercise](ex04.md#3-1-optional-exercise)
+ [Programming Ex.4](ex04.md#programming-ex-4)
+ [Debugging Tip](ex04.md#debugging-tip)
    + [Tips for classifying your own images](ex04.md#tips-for-classifying-your-own-images-)
+ [Bonus: Neural Network does not need order in pixels of an image as humans do](ex04.md#bonus-neural-network-does-not-need-order-in-pixels-of-an-image-as-humans-do)
    + [ex3_rand.m is a modified version of ex3.m](ex04.md#ex3_rand-m-is-a-modified-version-of-ex3-m)
    + [Why the order is Irrelevant for the Neural-Network](ex04.md#why-the-order-is-irrelevant-for-the-neural-network)
    + [Equivalent example of order irrelevancy](ex04.md#equivalent-example-of-order-irrelevancy)
+ [ex4 Tutorial for forward propagation and cost](ex04.md#ex4-tutorial-for-forward-propagation-and-cost)
    + [FAQ for Week 5 and programming exercise 4](ex04.md#faq-for-week-5-and-programming-exercise-4)


## Advice for Applying Machine Learning

+ [Evaluating a Learning Algorithm](10-Advice.md#evaluating-a-learning-algorithm)
    + [Deciding What to Try Next](10-Advice.md#deciding-what-to-try-next)
    + [Evaluating a Hypothesis](10-Advice.md#evaluating-a-hypothesis)
    + [Model Selection and Train/Validation/Test Sets](10-Advice.md#model-selection-and-train-validation-test-sets)
+ [Bias vs. Variance](10-Advice.md#bias-vs-variance)
    + [Diagnosing Bias vs. Variance](10-Advice.md#diagnosing-bias-vs-variance)
    + [Regularization and Bias/Variance](10-Advice.md#regularization-and-bias-variance)
    + [Learning Curves](10-Advice.md#learning-curves)
    + [Deciding What to Do Next Revisited](10-Advice.md#deciding-what-to-do-next-revisited)
+ [Review](10-Advice.md#review)
    + [Lecture Slides](10-Advice.md#lecture-slides)
    + [Errata](10-Advice.md#errata)
    + [Quiz: Advice for Applying Machine Learning](10-Advice.md#quiz-advice-for-applying-machine-learning)


## Programming Assignment: Regularized Linear Regression and Bias/Variance

+ 1 [Regularized Linear Regression](ex05.md#1-regularized-linear-regression)
    + 1.1 [Visualizing the dataset](ex05.md#1-1-visualizing-the-dataset)
    + 1.2 [Regularized linear regression cost function](ex05.md#1-2-regularized-linear-regression-cost-function)
    + 1.3 [Regularized linear regression gradient](ex05.md#1-3-regularized-linear-regression-gradient)
    + 1.4 [Fitting linear regression](ex05.md#1-4-fitting-linear-regression)
+ 2 [Bias-variance](ex05.md#2-bias-variance)
    + 2.1 [Learning curves](ex05.md#2-1-learning-curves)
+ 3 [Polynomial regression](ex05.md#3-polynomial-regression)
    + 3.1 [Learning Polynomial Regression](ex05.md#3-1-learning-polynomial-regression)
    + 3.2 [Adjusting the regularization parameter (Optional)](ex05.md#3-2-adjusting-the-regularization-parameter-optional-)
    + 3.3 [Selecting $\lambda$ using a cross validation set](ex05.md#3-3-selecting-7267-using-a-cross-validation-set)
    + 3.4 [Computing test set error (Optional)](ex05.md#3-4-computing-test-set-error-optional-)
    + 3.5 [Plotting learning curves with randomly selected (Optional)](ex05.md#3-5-plotting-learning-curves-with-randomly-selected-optional-)
+ [Programming Ex.5](ex05.md#programming-ex-5)
+ [Ex5 Tutorials](ex05.md#ex5-tutorials)
    + [ex5 tutorial linearRegCostFunction](ex05.md#ex5-tutorial-linearregcostfunction)
    + [Tutorial for polyFeatures()](ex05.md#tutorial-for-polyfeatures-)
    + [ex5: tips for learningCurve()](ex05.md#ex5-tips-for-learningcurve-)
    + [Validation curve question](ex05.md#validation-curve-question)
    + [FAQ for Week 6 and programming exercise 5](ex05.md#faq-for-week-6-and-programming-exercise-5)


## Machine Learning System Design

+ [Building a Spam Classifier](11-System.md#building-a-spam-classifier)
    + [Prioritizing What to Work On](11-System.md#prioritizing-what-to-work-on)
    + [Error Analysis](11-System.md#error-analysis)
+ [Handling Skewed Data](11-System.md#handling-skewed-data)
    + [Error Metrics for Skewed Classes](11-System.md#error-metrics-for-skewed-classes)
    + [Trading Off Precision and Recall](11-System.md#trading-off-precision-and-recall)
+ [Using Large Data Sets](11-System.md#using-large-data-sets)
+ [Review](11-System.md#review)
    + [Lecture Slides](11-System.md#lecture-slides)
    + [Quiz: Machine Learning System Design](11-System.md#quiz-machine-learning-system-design)


## Support Vector Machines

+ [Large Margin Classification](12-SVM.md#large-margin-classification)
    + [Optimization Objective](12-SVM.md#optimization-objective)
    + [Large Margin Intuition](12-SVM.md#large-margin-intuition)
    + [Mathematics Behind Large Margin Classification](12-SVM.md#mathematics-behind-large-margin-classification)
+ [Kernels](12-SVM.md#kernels)
    + [Kernels I](12-SVM.md#kernels-i)
    + [Kernels II](12-SVM.md#kernels-ii)
+ [SVMs in Practice: Using An SVM](12-SVM.md#svms-in-practice-using-an-svm)
+ [Review](12-SVM.md#review)
    + [Lecture Slides](12-SVM.md#lecture-slides)
    + [Errata](12-SVM.md#errata)
    + [Quiz: Support Vector Machines](12-SVM.md#quiz-support-vector-machines)


## Programming Assignment: Support Vector Machines

+ 1 [Support Vector Machines](ex06.md#1-support-vector-machines)
    + 1.1 [Example Dataset 1](ex06.md#1-1-example-dataset-1)
    + 1.2 [SVM with Gaussian Kernels](ex06.md#1-2-svm-with-gaussian-kernels)
+ 2 [Spam Classification](ex06.md#2-spam-classification)
    + 2.1 [Preprocessing Emails](ex06.md#2-1-preprocessing-emails)
    + 2.2 [Extracting Features from Emails](ex06.md#2-2-extracting-features-from-emails)
    + 2.3 [Training SVM for Spam Classification](ex06.md#2-3-training-svm-for-spam-classification)
    + 2.4 [Top Predictors for Spam](ex06.md#2-4-top-predictors-for-spam)
    + 2.5 [Try your own emails (optional)](ex06.md#2-5-try-your-own-emails-optional-)
    + 2.6 [Build your own dataset (optional)](ex06.md#2-6-build-your-own-dataset-optional-)
+ [Programming Ex.6](ex06.md#programming-ex-6)
    + [Update to ex6.m](ex06.md#update-to-ex6-m)
    + [Trouble with the contour plot visualizeBoundary.m](ex06.md#trouble-with-the-contour-plot-visualizeboundary-m-)
    + [processEmail no loop possible](ex06.md#processemail-no-loop-possible)
    + [Understanding SMO and the svmTrain() and svmPredict() methods](ex06.md#understanding-smo-and-the-svmtrain-and-svmpredict-methods)
    + [More SVM explanations](ex06.md#more-svm-explanations)
    + [Information on SVMLIB](ex06.md#information-on-svmlib)
    + [Using LIBSVM in MATLAB/Octave](ex06.md#using-libsvm-in-matlab-octave)
+ [Ex6 Tutorials](ex06.md#ex6-tutorials)
    + [Tutorial for emailfeatures()](ex06.md#tutorial-for-emailfeatures-)
    + [PROGRAMMING ASSIGNMENT FAQ](ex06.md#programming-assignment-faq)


## Dimensionality Reduction

+ [Motivation](14-Dimension.md#)motivation
    + [Motivation I: Data Compression](14-Dimension.md#motivation-i-data-compression)
    + [Motivation II: Visualization](14-Dimension.md#motivation-ii-visualization)
+ [Principal Component Analysis](14-Dimension.md#principal-component-analysis)
    + [Principal Component Analysis Problem Formulation](14-Dimension.md#principal-component-analysis-problem-formulation)
    + [Principal Component Analysis Algorithm](14-Dimension.md#principal-component-analysis-algorithm)
+ [Applying PCA](14-Dimension.md#applying-pca)
    + [Reconstruction from Compressed Representation](14-Dimension.md#reconstruction-from-compressed-representation)
    + [Choosing the Number of Principal Components](14-Dimension.md#choosing-the-number-of-principal-components)
    + [Advice for Applying PCA](14-Dimension.md#advice-for-applying-pca)
+ [Review](14-Dimension.md#review)
    + [Lecture Slides](14-Dimension.md#lecture-slides)
    + [Errata](14-Dimension.md#errata)
    + [Quiz: Principal Component Analysis](14-Dimension.md#quiz-principal-component-analysis)


## Programming Assignment: K-Means Clustering and PCA

+ 1   [K-means Clustering](ex07.md#1-k-means-clustering)
    + 1.1 [Implementing K-means](ex07.md#1-1-implementing-k-means)
    + 1.2 [K-means on example dataset](ex07.md#1-2-k-means-on-example-dataset)
    + 1.3 [Random initialization](ex07.md#1-3-random-initialization)
    + 1.4 [Image compression with K-means](ex07.md#1-4-image-compression-with-k-means)
    + 1.5 [Use your own image](ex07.md#1-5-use-your-own-image)
+ 2   [Principal Component Analysis](ex07.md#2-principal-component-analysis)
    + 2.1 [Example Dataset](ex07.md#2-1-example-dataset)
    + 2.2 [Implementing PCA](ex07.md#2-2-implementing-pca)
    + 2.3 [Dimensionality Reduction with PCA](ex07.md#2-3-dimensionality-reduction-with-pca)
    + 2.4 [Face image Dataset](ex07.md#2-4-face-image-dataset)
    + 2.5 [PCA for visualization (optional)](ex07.md#2-5-pca-for-visualization-optional-)
+ [Programming Exercise Tutorial](ex07.md#programming-exercise-tutorial)
    + [`indClosestCentroids()` tutorial](ex07.md#findclosestcentroids-tutorial)
    + [`computeCentroids()` tutorial](ex07.md#computecentroids-tutorial)
    + [Tutorials for ex7_pca functions](ex07.md#tutorials-for-ex7_pca-functions-pca-projectdata-recoverdata-)
    + [Programming Exercise 7:K-Means Clustering and PCA](ex07.md#programming-exercise-7-k-means-clustering-and-pca)
    + [FAQ for Week 8 and programming assignment 7](ex07.md#faq-for-week-8-and-programming-assignment-7)
    + [vectorized - computeCentroid](ex07.md#vectorized-computecentroid)


## Anomaly Detection

+ [Density Estimation](15-Detection.md#)
    + [Problem Motivation](15-Detection.md#)
    + [Gaussian Distribution](15-Detection.md#)
    + [Algorithm](15-Detection.md#)
+ [Building an Anomaly Detection System](15-Detection.md#)
    + [Developing and Evaluating an Anomaly Detection System](15-Detection.md#)
    + [Anomaly Detection vs. Supervised Learning](15-Detection.md#)
    + [Choosing What Features to Use](15-Detection.md#)
+ [Multivariate Gaussian Distribution (Optional)](15-Detection.md#)
    + [Multivariate Gaussian Distribution](15-Detection.md#)
    + [Anomaly Detection using the Multivariate Gaussian Distribution](15-Detection.md#)
+ [Review](15-Detection.md#)
    + [Lecture Slides](15-Detection.md#)
    + [Errata](15-Detection.md#)
    + [Quiz: Anomaly Detection](15-Detection.md#)

## Recommender Systems

+ [Predicting Movie Ratings](16-Recommend.md#)
    + [Problem Formulation](16-Recommend.md#)
    + [Content Based Recommendations](16-Recommend.md#)
+ [Collaborative Filtering](16-Recommend.md#)
    + [Collaborative Filtering](16-Recommend.md#)
    + [Collaborative Filtering Algorithm](16-Recommend.md#)
+ [Low Rank Matrix Factorization](16-Recommend.md#)
    + [Vectorization: Low Rank Matrix Factorization](16-Recommend.md#)
    + [Implementational Detail: Mean Normalization](16-Recommend.md#)
+ [Review](16-Recommend.md#)
    + [Lecture Slides](16-Recommend.md#)
    + [Errata](16-Recommend.md#)
    + [Quiz: Recommender Systems](16-Recommend.md#)


## Programming Assignment: Anomaly Detection and Recommender Systems

+ 1 [Anomaly detection](ex08.md#)
    + 1.1 [Gaussian distribution](ex08.md#)
    + 1.2 [Estimating parameters for a Gaussian](ex08.md#)
    + 1.3 [Selecting the threshold, $\epsilon$](ex08.md#)
    + 1.4 [High dimensional dataset](ex08.md#)
+ 2 [Recommender Systems](ex08.md#)
    + 2.1 [Movie ratings dataset](ex08.md#)
    + 2.2 [Collaborative filtering learning algorithm](ex08.md#)
        + 2.2.1 [Collaborative filtering cost function](ex08.md#)
        + 2.2.2 [Collaborative filtering gradient](ex08.md#)
        + 2.2.3 [Regularized cost function](ex08.md#)
        + 2.2.4 [Regularized gradient](ex08.md#)
    + 2.3 [Learning movie recommendations](ex08.md#)
        + 2.3.1 [Recommendations](ex08.md#)
+ [Vectorized Collaborative Filtering Cost Function & Gradients](ex08.md#)
    + [Notations](ex08.md#)
    + [Cost Function](ex08.md#)
    + [Gradients](ex08.md#)
+ [Programming Exercise Tutorial](ex08.md#)
    + [Error in `ex8_cofi.m`](ex08.md#)
    + [ex8 tutorial for `cofiCostFunc()`](ex08.md#)
    + [Programming Exercise 8](ex08.md#)
    + [FAQ for Week 9 and programming exercise 8](ex08.md#)
    + [Test cases for ex8_cofi - Recommender Systems](ex08.md#)
    + [Vectorized Implementation of Computing Gradient](ex08.md#)
    + [Computing gradient can be fully vectorized](ex08.md#)
    + [Some matrix math useful in vectorization](ex08.md#)


## Large Scale Machine Learning

+ [Gradient Descent with Large Datasets](17-LargeScale.md#)
    + [Learning With Large Datasets](17-LargeScale.md#)
    + [Stochastic Gradient Descent](17-LargeScale.md#)
    + [Mini-Batch Gradient Descent](17-LargeScale.md#)
    + [Stochastic Gradient Descent Convergence](17-LargeScale.md#)
+ [Advanced Topics](17-LargeScale.md#)
    + [Online Learning](17-LargeScale.md#)
    + [Map Reduce and Data Parallelism](17-LargeScale.md#)
+ [Review](17-LargeScale.md#)
    + [Lecture Slides](17-LargeScale.md#)
    + [Errata](17-LargeScale.md#)
    + [Quiz: Large Scale Machine Learning](17-LargeScale.md#)







