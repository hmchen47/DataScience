# Machine Learning

## Welcome

+ [Welcome to Machine Learning!](00-Welcome.md#welcome-to-machine-learning)
+ [Machine Learning Honor Code](00-Welcome.md#machine-learning-honor-code)
    + [Machine Learning Honor Code](00-Welcome.md#machine-learning-honor-code-1)
    + [Guidelines for Posting Code in Discussion Forums](00-Welcome.md#guidelines-for-posting-code-in-discussion-forums)
+ [How to Use Discussion Forums](00-Welcome.md#how-to-use-discussion-forums)
    + [Report Abuse](00-Welcome.md#report-abuse)
    + [Following](00-Welcome.md#following)
    + [Improving Your Posts](00-Welcome.md#improving-your-posts)
+ [Resources](00-Welcome.md#resources)
    + [Tutorials](00-Welcome.md#tutorials)
        + [ex1](00-Welcome.md#ex1)
        + [ex2](00-Welcome.md#ex2)
        + [ex3](00-Welcome.md#ex3)
        + [ex4](00-Welcome.md#ex4)
        + [ex5](00-Welcome.md#ex5)
        + [ex6](00-Welcome.md#ex6)
        + [ex7](00-Welcome.md#ex7)
        + [ex8](00-Welcome.md#ex8)
    + [Test Cases](00-Welcome.md#test-cases)
    + [Useful Resources](00-Welcome.md#useful-resources)
    + [Online E-Books](00-Welcome.md#online-e-books)
    + [Boosting](00-Welcome.md#boosting)
    + [Tips on Octave OS X](00-Welcome.md#tips-on-octave-os-x)
+ [Who are Mentors?](00-Welcome.md#who-are-mentors)
+ [Get to Know Your Classmates](00-Welcome.md#get-to-know-your-classmates)
+ [Frequently Asked Questions](00-Welcome.md#frequently-asked-questions)
+ [Programming Environment](00-Welcome.md#programming-environment)
    + [Environment Setup Instructions](00-Welcome.md#environment-setup-instructions)
    + [Setting Up Your Programming Assignment Environment](00-Welcome.md#setting-up-your-programming-assignment-environment)
    + [Access MATLAB Online and Upload the Exercise Files](00-Welcome.md#access-matlab-online-and-upload-the-exercise-files)
    + [Installing Octave on Windows](00-Welcome.md#installing-octave-on-windows)
    + [Installing Octave on Mac OS X (10.10 Yosemite and 10.9 Mavericks and Later)](00-Welcome.md#installing-octave-on-mac-os-x-1010-yosemite-and-109-mavericks-and-later)
    + [Installing Octave on Mac OS X (10.8 Mountain Lion and Earlier)](00-Welcome.md#installing-octave-on-mac-os-x-108-mountain-lion-and-earlier)
    + [Installing Octave on GNU/Linux](00-Welcome.md#installing-octave-on-gnulinux)
    + [More Octave/MATLAB resources](00-Welcome.md#more-octavematlab-resources)
+ [Submitting Programming Assignments](00-Welcome.md#submitting-programming-assignments)
    + [Working on and Submitting Programming Assignments](00-Welcome.md#working-on-and-submitting-programming-assignments)
    + [Programming tips from Mentors](00-Welcome.md#programming-tips-from-mentors)
    + [Programming Exercise Tutorials (list)](00-Elecome.md#programming-exercisetutorials-list)


## Introduction

+ [Welcome](01-Intro.md#lecture-notes)
+ [What is Machine Learning?](01-Intro.md#what-is-machine-learning)
+ [Supervised Learning](01-Intro.md#supervised-learning)
+ [Unsupervised Learning](01-Intro.md#unsupervised-learning)
+ [Review](01-Intro.md#review)
    + [Lecture Slides](01-Intro.md#lecture-slides)
    + [Errata](01-Intro.md#errata)
+ [Quiz: Introduction](01-Intro.md#quiz-introduction)


## Linear Regression with One Variable

+ [Model and Cost Function](02-ModelCost.md#model-representation)
    + [Model Representation](02-ModelCost.md#cost-function)
    + [Cost Function](02-ModelCost.md#)
    + [Cost Function - Intuition I](02-ModelCost.md#cost-function---intuition-i)
    + [Cost Function - Intuition II](02-ModelCost.md#cost-function---intuition-ii)
+ [Parameter Learning](02-ModelCost.md#parameter-learning)
    + [Gradient Descent](02-ModelCost.md#gradient-descent)
    + [Gradient Descent Intuition](02-ModelCost.md#gradient-descent-intuition)
    + [Gradient Descent For Linear Regression](02-ModelCost.md#gradient-descent-for-linear-regression)
+ [Review](02-ModelCost.md#review)
    + [Lecture Slides](02-ModelCost.md#lecture-slides)
    + [Errata](02-ModelCost.md#errata)
+ [Quiz: Linear Regression with One Variable](02-ModelCost.md#quiz-linear-regression-with-one-variable)


## Linear Algebra Review

+ [Matrices and Vectors](03-LAlgebra.md#matrices-and-vectors)
+ [Addition and Scalar Multiplication](03-LAlgebra.md#addition-and-scalar-multiplication)
+ [Matrix Vector Multiplication](03-LAlgebra.md#matrix-vector-multiplication)
+ [Matrix Matrix Multiplication](03-LAlgebra.md#matrix-matrix-multiplication)
+ [Matrix Multiplication Properties](03-LAlgebra.md#matrix-multiplication-properties)
+ [Inverse and Transpose](03-LAlgebra.md#inverse-and-transpose)
+ [Review](03-LAlgebra.md#review)
    + [Lecture Slides](03-LAlgebra.md#lecture-slides)
    + [Errata](03-LAlgebra.md#errata)
+ [Practice Quiz: Linear Algebra](03-LAlgebra.md#practice-quiz-linear-algebra)



## Linear Regression with Multiple Variables

+ [Multivariate Linear Regression](04-LRegMVar.md#multivariate-linear-regression)
    + [Multiple Features](04-LRegMVar.md#multiple-features)
    + [Gradient Descent for Multiple ](04-LRegMVar.md#gradient-descent-for-multiple)
    + [Gradient Descent in Practice I - Feature ](04-LRegMVar.md#gradient-descent-in-practice-i---feature)
    + [Gradient Descent in Practice II - Learning Rate](04-LRegMVar.md#gradient-descent-in-practice-ii---learning-rate)
    + [Features and Polynomial Regression](04-LRegMVar.md#features-and-polynomial-regression)
+ [Computing Parameters Analytically](04-LRegMVar.md#computing-parameters-analytically)
    + [Normal Equation](04-LRegMVar.md#normal-equation)
    + [Normal Equation Noninvertibility](04-LRegMVar.md#normal-equation-noninvertibility)
+ [Review](04-LRegMVar.md#review)
    + [Lecture Slides](04-LRegMVar.md#lecture-slides)
    + [Errata](04-LRegMVar.md#errors-in-the-video-lectures)
+ [Quiz: Linear Regression with Multiple Variables](04-LRegMVar.md#quiz-linear-regression-with-multiple-variables)

## Octave/Matlab Tutorial

+ [Basic Operations](05-Octave.md#basic-operations)
+ [Moving Data Around](05-Octave.md#moving-data-around)
+ [Computing on Data](05-Octave.md#computing-on-data)
+ [Plotting Data](05-Octave.md#plotting-data)
+ [Control Statements: for, while, if statement](05-Octave.md#control-statements-for-while-if-statement)
+ [Vectorization](05-Octave.md#vectorization)
+ [Review](05-Octave.md#review)
    + [Lecture Slides](05-Octave.md#lecture-slides)
    + [Errata](05-Octave.md#errata)
    + [Quiz: Octave/Matlab Tutorial](05-Octave.md#quiz-octavematlab-tutorial)


## Programming Assignment 1: Linear Regression

## Logistic Regression

+ [Classification and Representation](06-Logistic.md#classification-and-representation)
    + [Classification](06-Logistic.md#classification)
    + [Hypothesis Representation](06-Logistic.md#hypothesis-representation)
    + [Decision Boundary](06-Logistic.md#decision-boundary)
+ [Logistic Regression Model](06-Logistic.md#logistic-regression-model)
    + [Cost Function](06-Logistic.md#cost-function)
    + [Simplified Cost Function and Gradient Descent](06-Logistic.md#simplified-cost-function-and-gradient-descent)
    + [Advanced Optimization](06-Logistic.md#advanced-optimization)
+ [Multiclass Classification: One-vs-all](06-Logistic.md#multiclass-classification-one-vs-all)
+ [Review](06-Logistic.md#review)
    + [Lecture Slides](06-Logistic.md#lecture-slides)
    + [Errata](06-Logistic.md#errata)
    + [Quiz: Logistic Regression](06-Logistic.md#quiz-logistic-regression)


## Regularization: Solving the Problem of Overfitting

+ [The Problem of Overfitting](07-Overfit.md#the-problem-of-overfitting)
+ [Cost Function](07-Overfit.md#cost-function)
+ [Regularized Linear Regression](07-Overfit.md#regularized-linear-regression)
+ [Regularized Logistic Regression](07-Overfit.md#regularized-logistic-regression)
+ [Review](07-Overfit.md#review)
    + [Lecture Slides](07-Overfit.md#lecture-slides)
    + [Errata]()(07-Overfit.md#errata)
    + [Quiz: Regularization](07-Overfit.md#quiz-regularization)



## Programming Assignment: Logistic Regression

+ [Logistic Regression](ex02.md#logistic-regression)
    + [Visualizing the data](ex02.md#visualizing-the-data)
    + [Implementation](ex02.md#implementation)
+ [Regularized logistic regression](ex02.md#regularized-logistic-regression)
    + [Visualizing the data](ex02.md#visualizing-the-data-1)
    + [Feature mapping](ex02.md#feature-mapping)
    + [Cost function and gradient](ex02.md#cost-function-and-gradient)
    + [Plotting the decision boundary](ex02.md#plotting-the-decision-boundary)
    + [Optional exercises](ex02.md#optional-exercises)
+ [Programming Ex.2](ex02.md#programming-ex2)
    + [Gradient and theta values for ex2.m](ex02.md#gradient-and-theta-values-forex2m)
    + [mapFeature() discussion](ex02.md#mapfeature-discussion)
    + [plotData.m - color attributes](ex02.md#plotdatam---color-attributes)
    + [Logistic Regression Gradient](ex02.md#logistic-regression-gradient)
    + [Sigmoid function](ex02.md#sigmoid-function)
    + [Decision Boundary](ex02.md#decision-boundary)

## Neural Networks: Representation

+ [Motivations](08-NNRepres.md#motivations)
    + [Non-linear Hypotheses](08-NNRepres.md#non-linear-hypotheses)
    + [Neurons and the Brain](08-NNRepres.md#neurons-and-the-brain)
+ [Neural Networks](08-NNRepres.md#neural-networks)
    + [Model Representation I](08-NNRepres.md#model-representation-i)
    + [Model Representation II](08-NNRepres.md#model-representation-ii)
+ [Applications](08-NNRepres.md#applications)
    + [Examples and Intuitions I](08-NNRepres.md#examples-and-intuitions-i)
    + [Examples and Intuitions II](08-NNRepres.md#examples-and-intuitions-ii)
    + [Multiclass Classification](08-NNRepres.md#multiclass-classification)
+ [Review](08-NNRepres.md#review)
    + [Lecture Slides](08-NNRepres.md#lecture-slides)
    + [Errata](08-NNRepres.md#errata)
    + [Quiz: Neural Networks: Representation](08-NNRepres.md#quiz-neural-networks-representation)



## Programming Assignment: Multi-class Classification and Neural Networks

+ [Multi-class Classification](ex03.md#multi-class-classification)
    + [Dataset](ex03.md#dataset)
    + [Visualizing the data](ex03.md#visualizing-the-data)
    + [Vectorizing Logistic Regression](ex03.md#vectorizing-logistic-regression)
    + [One-vs-all Classification](ex03.md#one-vs-all-classification)
+ [Neural Networks](ex03.md#neural-networks)
    + [Model representation](ex03.md#model-representation)
    + [Feedforward Propagation and Prediction](ex03.md#feedforward-propagation-and-prediction)
+ [Debugging Tip](ex03.md#debugging-tip)
    + [1.4.1 One-vs-all Prediction](ex03.md#141-one-vs-all-prediction)
    + [2.2 Feedforward Propagation and Prediction (Neural network)](ex03.md#22-feedforward-propagation-and-prediction-neural-network)
    + [Prediction of an image outside the dataset (Neural Network)](ex03.md#prediction-of-an-image-outside-the-dataset-neural-network)


## Neural Networks: Learning

+ [Cost Function and Backpropagation](09-NNLearn.md#)
    + [Cost](09-NNLearn.md#)
    + [Backpropagation Algorithm](09-NNLearn.md#)
    + [Backpropagation Intuition](09-NNLearn.md#)
+ [Backpropagation in Practice](09-NNLearn.md#)
    + [Implementation Note: Unrolling Parameters](09-NNLearn.md#)
    + [Gradient Checking](09-NNLearn.md#)
    + [Random Initialization](09-NNLearn.md#)
    + [Putting It Together](09-NNLearn.md#)
+ [Application of Neural Networks-Autonomous Driving](09-NNLearn.md#)
+ [Review](09-NNLearn.md#)
    + [Lecture Slides](09-NNLearn.md#)
    + [Errata](09-NNLearn.md#)
    + [Quiz: Neural Networks: Learning](09-NNLearn.md#)
    

## Programming Assignment: Neural Network Learning

+ 1. [Neural Network](ex04.md#)
    + 1.1 [Visualizing the data](ex04.md#)
    + 1.2 [Model representation](ex04.md#)
    + 1.3 [Feedbackforward and cost function](ex04.md#)
    + 1.4 [Regularized cost function](ex04.md#)
+ 2. [Backpropagation](ex04.md#)
    + 2.1 [Sigmoid gradient](ex04.md#)
    + 2.2 [Random initialization](ex04.md#)
    + 2.3 [Backpropagation](ex04.md#)
    + 2.4 [Gradient checking](ex04.md#)
    + 2.5 [Regularized Neural Networks](ex04.md#)
    + 2.6 [Learning parameters using `fmincg`](ex04.md#)
+ 3. [Visualizing the hidden layer](ex04.md#)
    + 3.1 [Optional exercise](ex04.md#)
+ [Programming Ex.4](ex04.md#)

## Advice for Applying Machine Learning

+ [Evaluating a Learning Algorithm](10-Advice.md#)
    + [Deciding What to Try Next](10-Advice.md#)
    + [Evaluating a Hypothesis](10-Advice.md#)
    + [Model Selection and Train/Validation/Test Sets](10-Advice.md#)
+ [Bias vs. Variance](10-Advice.md#)
    + [Diagnosing Bias vs. Variance](10-Advice.md#)
    + [Regularization and Bias/Variance](10-Advice.md#)
    + [Learning Curves](10-Advice.md#)
    + [Deciding What to Do Next Revisited](10-Advice.md#)
+ [Review](10-Advice.md#)
    + [Lecture Slides](10-Advice.md#)
    + [Errata](10-Advice.md#)
    + [Quiz: Advice for Applying Machine Learning](10-Advice.md#)


## Programming Assignment: Regularized Linear Regression and Bias/Variance

+ 1 [Regularized Linear Regression](ex05.md#)
    + 1.1 [Visualizing the dataset](ex05.md#)
    + 1.2 [Regularized linear regression cost function](ex05.md#)
    + 1.3 [Regularized linear regression gradient](ex05.md#)
    + 1.4 [Fitting linear regression](ex05.md#)
+ 2 [Bias-variance](ex05.md#)
    + 2.1 [Learning curves](ex05.md#)
+ 3 [Polynomial regression](ex05.md#)
    + 3.1 [Learning Polynomial Regression](ex05.md#)
    + 3.2 [Adjusting the regularization parameter (Optional)](ex05.md#)
    + 3.3 [Selecting $\lambda$ using a cross validation set](ex05.md#)
    + 3.4 [Computing test set error (Optional)](ex05.md#)
    + 3.5 [Plotting learning curves with randomly selected (Optional)](ex05.md#)
+ [Programming Ex.5](ex05.md#)
+ [Ex5 Tutorials](ex05.md#)
    + [ex5 tutorial linearRegCostFunction](ex05.md#)
    + [Tutorial for polyFeatures()](ex05.md#)
    + [ex5: tips for learningCurve()](ex05.md#)
    + [Validation curve question](ex05.md#)
    + [FAQ for Week 6 and programming exercise 5](ex05.md#)


## Machine Learning System Design

+ [Building a Spam Classifier](11-System.md#)
    + [Prioritizing What to Work On](11-System.md#)
    + [Error Analysis](11-System.md#)
+ [Handling Skewed Data](11-System.md#)
    + [Error Metrics for Skewed Classes](11-System.md#)
    + [Trading Off Precision and Recall](11-System.md#)
+ [Using Large Data Sets](11-System.md#)
+ [Review](11-System.md#)
    + [Lecture Slides](11-System.md#)
    + [Quiz: Machine Learning System Design](11-System.md#)


## Support Vector Machines

+ [Large Margin Classification](12-SVM.md#)
    + [Optimization Objective](12-SVM.md#)
    + [Large Margin Intuition](12-SVM.md#)
    + [Mathematics Behind Large Margin Classification](12-SVM.md#)
+ [Kernels](12-SVM.md#)
    + [Kernels I](12-SVM.md#)
    + [Kernels II](12-SVM.md#)
+ [SVMs in Practice: Using An SVM](12-SVM.md#)
+ [Review](12-SVM.md#)
    + [Lecture Slides](12-SVM.md#)
    + [Errata](12-SVM.md#)
    + [Quiz: Support Vector Machines](12-SVM.md#)


## Programming Assignment: Support Vector Machines

+ 1 [Support Vector Machines](ex06.md#)
    + 1.1 [Example Dataset 1](ex06.md#)
    + 1.2 [SVM with Gaussian Kernels](ex06.md#)
+ 2 [Spam Classification](ex06.md#)
    + 2.1 [Preprocessing Emails](ex06.md#)
    + 2.2 [Extracting Features from Emails](ex06.md#)
    + 2.3 [Training SVM for Spam Classification](ex06.md#)
    + 2.4 [Top Predictors for Spam](ex06.md#)
    + 2.5 [Try your own emails (optional)](ex06.md#)
    + 2.6 [Build your own dataset (optional)](ex06.md#)
+ [Programming Ex.6](ex06.md#)
+ [Ex6 Tutorials](ex06.md#)
    + [Tutorial for emailfeatures()](ex06.md#)
    + [FAQ for Week 7 and programming exercise 6](ex06.md#)


## Unsupervised Learning: Clustering

+ [Unsupervised Learning: Introduction](13-Clustering.md#)
+ [K-Means Algorithm](13-Clustering.md#)
+ [Optimization Objective](13-Clustering.md#)
+ [Random Initialization](13-Clustering.md#)
+ [Choosing the Number of Clusters](13-Clustering.md#)
+ [Review](13-Clustering.md#)
    + [Lecture Slides](13-Clustering.md#)
    + [Errata](13-Clustering.md#)
+ [Quiz: Unsupervised Learning](13-Clustering.md#)


## Dimensionality Reduction

+ [Motivation](14-Dimension.md#)
    + [Motivation I: Data Compression](14-Dimension.md#)
    + [Motivation II: Visualization](14-Dimension.md#)
+ [Principal Component Analysis](14-Dimension.md#)
    + [Principal Component Analysis Problem Formulation](14-Dimension.md#)
    + [Principal Component Analysis Algorithm](14-Dimension.md#)
+ [Applying PCA](14-Dimension.md#)
    + [Reconstruction from Compressed Representation](14-Dimension.md#)
    + [Choosing the Number of Principal Components](14-Dimension.md#)
    + [Advice for Applying PCA](14-Dimension.md#)
+ [Review](14-Dimension.md#)
    + [Lecture Slides](14-Dimension.md#)
    + [Errata](14-Dimension.md#)
    + [Quiz: Principal Component Analysis](14-Dimension.md#)


## Programming Assignment: K-Means Clustering and PCA

+ 1   [K-means Clustering](ex07.md#)
    + 1.1 [Implementing K-means](ex07.md#)
    + 1.2 [K-means on example dataset](ex07.md#)
    + 1.3 [Random initialization](ex07.md#)
    + 1.4 [Image compression with K-means1.5](ex07.md#)
    + 1.5 [Use your own image](ex07.md#)
+ 2   [Principal Component Analysis](ex07.md#)
    + 2.1 [Example Dataset](ex07.md#)
    + 2.2 [Implementing PCA](ex07.md#)
    + 2.3 [Dimensionality Reduction with PCA](ex07.md#)
    + 2.4 [Face image Dataset](ex07.md#)
    + 2.5 [PCA for visualization (optional)](ex07.md#)
+ [Programming Exercise Tutorial](ex07.md#)
    + [`indClosestCentroids()` tutorial](ex07.md#)
    + [`computeCentroids()` tutorial](ex07.md#)
    + [Tutorials for ex7_pca functions](ex07.md#)
    + [Programming Exercise 7:K-Means Clustering and PCA](ex07.md#)
    + [FAQ for Week 8 and programming assignment 7](ex07.md#)
    + [vectorized - computeCentroid](ex07.md#)




Quiz https://github.com/mGalarnyk/datasciencecoursera/tree/master/Stanford_Machine_Learning


